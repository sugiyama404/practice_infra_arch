{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57b44c8",
   "metadata": {},
   "source": [
    "# Analyze Test Results and Generate Report (saga_pattern)\n",
    "\n",
    "This notebook helps analyze test outputs from `saga_pattern` test runs, compute metrics, visualize results, and generate an English report file `saga_pattern/analyze_test_results.md`.\n",
    "\n",
    "Sections:\n",
    "1. Project setup: create directories and English-named report file\n",
    "2. Load test result files (CSV / JSON / logs)\n",
    "3. Parse and normalize filenames and encodings (rename non-ASCII to English)\n",
    "4. Data cleaning and preprocessing\n",
    "5. Compute key metrics and statistical summaries\n",
    "6. Visualizations (time series, histograms, heatmaps)\n",
    "7. Export results and write English markdown report (`saga_pattern/analyze_test_results.md`)\n",
    "8. Unit tests for analysis functions (pytest)\n",
    "9. Execute notebook programmatically and capture outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f76b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Project setup - create directories and English-named report file\n",
    "from pathlib import Path\n",
    "\n",
    "saga_dir = Path.cwd()\n",
    "report_path = saga_dir / 'analyze_test_results.md'\n",
    "\n",
    "# Create report file if it doesn't exist\n",
    "if not report_path.exists():\n",
    "    report_path.write_text('# Test Results Analysis\\n\\nReport generated by analyze_test_results.ipynb\\n')\n",
    "\n",
    "print('Report path:', report_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c72b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2: Load test result files (CSV / JSON / logs)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "artifacts_dir = saga_dir / 'test_artifacts'\n",
    "artifacts_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Discover files (csv, json, txt, log)\n",
    "file_patterns = ['*.csv', '*.json', '*.log', '*.txt']\n",
    "files = []\n",
    "for pat in file_patterns:\n",
    "    files.extend(list(artifacts_dir.glob(pat)))\n",
    "\n",
    "print('Found files:', files)\n",
    "\n",
    "# Load CSV/JSON into DataFrame list\n",
    "frames = []\n",
    "for f in files:\n",
    "    if f.suffix == '.csv':\n",
    "        frames.append(pd.read_csv(f))\n",
    "    elif f.suffix == '.json':\n",
    "        try:\n",
    "            df = pd.read_json(f)\n",
    "        except ValueError:\n",
    "            with open(f, 'r') as fh:\n",
    "                data = json.load(fh)\n",
    "            df = pd.json_normalize(data)\n",
    "        frames.append(df)\n",
    "    else:\n",
    "        # Simple log parser: read lines into DataFrame\n",
    "        with open(f, 'r', encoding='utf-8', errors='replace') as fh:\n",
    "            lines = [l.strip() for l in fh if l.strip()]\n",
    "        df = pd.DataFrame({'raw': lines})\n",
    "        frames.append(df)\n",
    "\n",
    "if frames:\n",
    "    unified = pd.concat(frames, ignore_index=True, sort=False)\n",
    "else:\n",
    "    unified = pd.DataFrame()\n",
    "\n",
    "print('Unified shape:', unified.shape)\n",
    "unified.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3: Parse and normalize filenames and encodings (rename non-ASCII to English)\n",
    "import os\n",
    "\n",
    "def normalize_name(p: Path) -> Path:\n",
    "    # Simple mapping\n",
    "    mapping = {\n",
    "        'テスト結果を分析する.md': 'analyze_test_results.md'\n",
    "    }\n",
    "    if p.name in mapping:\n",
    "        return p.with_name(mapping[p.name])\n",
    "    # fallback: replace non-ascii with '_'\n",
    "    name = ''.join((c if ord(c) < 128 else '_') for c in p.name)\n",
    "    return p.with_name(name)\n",
    "\n",
    "# Find files with non-ascii name in saga_dir\n",
    "for p in saga_dir.iterdir():\n",
    "    if any(ord(c) >= 128 for c in p.name):\n",
    "        target = normalize_name(p)\n",
    "        try:\n",
    "            p.rename(target)\n",
    "            print(f'Renamed {p.name} -> {target.name}')\n",
    "        except Exception as e:\n",
    "            print('Rename failed:', p, e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d03e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4: Data cleaning and preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "# Example cleaning function\n",
    "\n",
    "def clean_unified(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    # normalize column names\n",
    "    df.columns = [str(c).strip().lower().replace(' ', '_') for c in df.columns]\n",
    "    # parse timestamps if present\n",
    "    for col in df.columns:\n",
    "        if 'time' in col or 'timestamp' in col or 'date' in col:\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            except Exception:\n",
    "                pass\n",
    "    # numeric conversion\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        # try to convert common numeric columns\n",
    "        if any(k in col for k in ('time', 'duration', 'ms', 'sec')):\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    # drop rows where everything is NaN\n",
    "    df = df.dropna(how='all')\n",
    "    return df\n",
    "\n",
    "unified = clean_unified(unified)  # reuse unified from earlier cell\n",
    "print('After cleaning shape:', unified.shape)\n",
    "unified.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927f430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5: Compute key metrics and statistical summaries\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(df: pd.DataFrame) -> dict:\n",
    "    metrics = {}\n",
    "    total = len(df)\n",
    "    metrics['total'] = total\n",
    "    if 'status' in df.columns:\n",
    "        passes = (df['status'].str.lower() == 'success').sum()\n",
    "        metrics['passes'] = int(passes)\n",
    "        metrics['pass_rate'] = passes / total if total else None\n",
    "    # durations\n",
    "    dur_cols = [c for c in df.columns if 'duration' in c or 'response_time' in c or 'ms' in c]\n",
    "    if dur_cols:\n",
    "        d = df[dur_cols].apply(pd.to_numeric, errors='coerce')\n",
    "        metrics['duration_mean'] = d.mean(numeric_only=True).to_dict()\n",
    "        metrics['duration_median'] = d.median(numeric_only=True).to_dict()\n",
    "    # failure counts by scenario\n",
    "    if 'scenario' in df.columns:\n",
    "        metrics['failure_counts'] = df[df['status'].str.lower() != 'success']['scenario'].value_counts().to_dict()\n",
    "    return metrics\n",
    "\n",
    "metrics = compute_metrics(unified)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85e30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6: Visualizations (time series, histograms, heatmaps)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Time series of failures\n",
    "if 'timestamp' in unified.columns or 'created_at' in unified.columns:\n",
    "    time_col = 'timestamp' if 'timestamp' in unified.columns else 'created_at'\n",
    "    df_time = unified.copy()\n",
    "    df_time[time_col] = pd.to_datetime(df_time[time_col], errors='coerce')\n",
    "    df_time = df_time.dropna(subset=[time_col])\n",
    "    df_time['date'] = df_time[time_col].dt.floor('D')\n",
    "    daily = df_time.groupby(['date', 'status']).size().unstack(fill_value=0)\n",
    "    if not daily.empty:\n",
    "        daily.plot(kind='line', figsize=(10,4))\n",
    "        plt.title('Daily test counts by status')\n",
    "        plt.show()\n",
    "\n",
    "# Histogram of response_time\n",
    "if 'response_time' in unified.columns:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(unified['response_time'].dropna(), kde=False)\n",
    "    plt.title('Response Time Distribution')\n",
    "    plt.xlabel('seconds')\n",
    "    plt.show()\n",
    "\n",
    "# Heatmap example: failures by scenario vs status (pivot)\n",
    "if 'scenario' in unified.columns and 'status' in unified.columns:\n",
    "    pivot = unified.pivot_table(index='scenario', columns='status', aggfunc='size', fill_value=0)\n",
    "    if not pivot.empty:\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.heatmap(pivot, annot=True, fmt='d', cmap='Reds')\n",
    "        plt.title('Failures by Scenario and Status')\n",
    "        plt.show()\n",
    "\n",
    "# Save figures path\n",
    "figs_dir = saga_dir / 'analysis_figs'\n",
    "figs_dir.mkdir(exist_ok=True)\n",
    "plt.savefig(figs_dir / 'last_plot.png')\n",
    "print('Saved example fig to', figs_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 7: Export results and write English markdown report (saga_pattern/analyze_test_results.md)\n",
    "report_md = saga_dir / 'analyze_test_results.md'\n",
    "\n",
    "report_lines = []\n",
    "report_lines.append('# Test Results Analysis')\n",
    "report_lines.append('')\n",
    "report_lines.append('## Summary Metrics')\n",
    "for k, v in metrics.items():\n",
    "    report_lines.append(f'- {k}: {v}')\n",
    "\n",
    "# attach example figure\n",
    "last_fig = figs_dir / 'last_plot.png'\n",
    "if last_fig.exists():\n",
    "    report_lines.append('\\n## Figures')\n",
    "    report_lines.append(f'![]({last_fig.name})')\n",
    "\n",
    "report_md.write_text('\\n'.join(report_lines), encoding='utf-8')\n",
    "print('Wrote report to', report_md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2dd6b0",
   "metadata": {},
   "source": [
    "## Section 8: Unit tests (pytest)\n",
    "\n",
    "Create tests under `tests/` for parsing, cleaning, and metric functions. Example test snippet:\n",
    "\n",
    "```python\n",
    "# tests/test_analysis.py\n",
    "import pandas as pd\n",
    "from analyze_test_results import clean_unified, compute_metrics\n",
    "\n",
    "def test_clean_unified_basic():\n",
    "    df = pd.DataFrame({'status': ['success', 'failure'], 'response_time': ['0.1', '0.2']})\n",
    "    out = clean_unified(df)\n",
    "    assert 'response_time' in out.columns\n",
    "\n",
    "def test_compute_metrics_counts():\n",
    "    df = pd.DataFrame({'status': ['success','failure','success']})\n",
    "    m = compute_metrics(df)\n",
    "    assert m['total'] == 3\n",
    "    assert m['passes'] == 2\n",
    "```\n",
    "\n",
    "Run tests with:\n",
    "\n",
    "```bash\n",
    "pytest -q\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad553c5",
   "metadata": {},
   "source": [
    "## Section 9: Execute notebook programmatically and capture outputs\n",
    "\n",
    "You can run this notebook non-interactively with nbconvert or papermill. Examples:\n",
    "\n",
    "```bash\n",
    "# Run in-place with nbconvert\n",
    "jupyter nbconvert --to notebook --execute analyze_test_results.ipynb --output analyze_test_results.executed.ipynb\n",
    "\n",
    "# Using papermill (parameterize if needed)\n",
    "papermill analyze_test_results.ipynb analyze_test_results.executed.ipynb\n",
    "```\n",
    "\n",
    "Capture stderr/stdout to files when running the commands in a shell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "{\n",
    "# --- DB接続と可視化セルの追加 ---\n",
    "# 追加セル: MySQLからデータを読み込み、3つのグラフを描画します。\n",
    "\"\"\"\n",
    "注意: 下の connection string を実環境の user/password/host/port に書き換えてください。\n",
    "\"\"\"\n",
    "}\n",
    "# ...existing code...\n",
    "{\n",
    "# 新規セル (Python)\n",
    "\"!pip install pymysql sqlalchemy seaborn --quiet\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlalchemy\n",
    "import time\n",
    "\n",
    "# DB接続設定（環境に合わせて書き換え）\n",
    "DB_USER = \"root\"\n",
    "DB_PASS = \"password\"\n",
    "DB_HOST = \"127.0.0.1\"\n",
    "DB_PORT = 3306\n",
    "DB_NAME = \"cloudmart_saga\"\n",
    "CONN_STR = f\"mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "engine = sqlalchemy.create_engine(CONN_STR)\n",
    "\n",
    "# --- クエリ: E2E レイテンシ（ms） ---\n",
    "q_e2e = \"\"\"\n",
    "SELECT order_id,\n",
    "       created_at,\n",
    "       COALESCE(confirmed_at, delivered_at, cancelled_at) AS finished_at,\n",
    "       TIMESTAMPDIFF(MILLISECOND, created_at, COALESCE(confirmed_at, delivered_at, cancelled_at)) AS e2e_ms\n",
    "FROM orders\n",
    "WHERE created_at IS NOT NULL\n",
    "  AND COALESCE(confirmed_at, delivered_at, cancelled_at) IS NOT NULL;\n",
    "\"\"\"\n",
    "df_e2e = pd.read_sql_query(q_e2e, engine, parse_dates=['created_at','finished_at'])\n",
    "\n",
    "# --- クエリ: 収束時間（events）秒 ---\n",
    "q_conv = \"\"\"\n",
    "SELECT aggregate_id,\n",
    "       MIN(processed_at) AS first_at,\n",
    "       MAX(processed_at) AS last_at,\n",
    "       TIMESTAMPDIFF(SECOND, MIN(processed_at), MAX(processed_at)) AS convergence_s,\n",
    "       COUNT(*) AS event_count\n",
    "FROM events\n",
    "GROUP BY aggregate_id;\n",
    "\"\"\"\n",
    "df_conv = pd.read_sql_query(q_conv, engine, parse_dates=['first_at','last_at'])\n",
    "\n",
    "# --- クエリ: サガのステップタイムライン（補償の可視化） ---\n",
    "q_saga_steps = \"\"\"\n",
    "SELECT sl.saga_id, sl.step_number, sl.step_name, sl.service_name, sl.status,\n",
    "       sl.started_at, sl.completed_at, si.status AS saga_status\n",
    "FROM saga_step_logs sl\n",
    "LEFT JOIN saga_instances si ON sl.saga_id = si.saga_id\n",
    "ORDER BY sl.saga_id, sl.step_number;\n",
    "\"\"\"\n",
    "df_steps = pd.read_sql_query(q_saga_steps, engine, parse_dates=['started_at','completed_at'])\n",
    "\n",
    "# --- 1) E2E レイテンシ: p50/p95/p99 と箱ひげ／ヒストグラム ---\n",
    "p50 = df_e2e['e2e_ms'].quantile(0.5)\n",
    "p95 = df_e2e['e2e_ms'].quantile(0.95)\n",
    "p99 = df_e2e['e2e_ms'].quantile(0.99)\n",
    "\n",
    "print(f\"E2E latency (ms) p50={p50:.1f}, p95={p95:.1f}, p99={p99:.1f}\")\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.boxplot(x=df_e2e['e2e_ms'])\n",
    "plt.title('E2E Latency (ms) - boxplot')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.histplot(df_e2e['e2e_ms'], bins=30, kde=False)\n",
    "plt.axvline(p50, color='C1', linestyle='--', label=f'p50={p50:.0f}ms')\n",
    "plt.axvline(p95, color='C2', linestyle='--', label=f'p95={p95:.0f}ms')\n",
    "plt.legend()\n",
    "plt.title('E2E Latency Histogram (ms)')\n",
    "plt.xlabel('latency (ms)')\n",
    "plt.show()\n",
    "\n",
    "# --- 2) 収束時間ヒストグラム（seconds） ---\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df_conv['convergence_s'], bins=[0,1,5,30,300,3600], discrete=False)\n",
    "plt.title('Convergence Time Histogram (s)')\n",
    "plt.xlabel('seconds to converge')\n",
    "plt.show()\n",
    "\n",
    "# 確認用の要約\n",
    "print(df_conv[['aggregate_id','convergence_s','event_count']].sort_values('convergence_s', ascending=False).head())\n",
    "\n",
    "# --- 3) 補償／サガタイムライン（Gantt風） ---\n",
    "# prepare times relative to min time for plotting\n",
    "if not df_steps.empty:\n",
    "    df_steps['start_ts'] = df_steps['started_at'].astype('int64') // 10**9\n",
    "    df_steps['end_ts'] = df_steps['completed_at'].astype('int64') // 10**9\n",
    "    # fallback for null completed_at\n",
    "    df_steps['end_ts'] = df_steps['end_ts'].fillna(df_steps['start_ts'] + 1)\n",
    "    base = df_steps['start_ts'].min()\n",
    "    df_steps['start_rel'] = df_steps['start_ts'] - base\n",
    "    df_steps['dur_s'] = df_steps['end_ts'] - df_steps['start_ts']\n",
    "\n",
    "    # one subplot per saga (or group a few if many)\n",
    "    sagas = df_steps['saga_id'].unique()\n",
    "    fig_h = max(4, len(sagas)*1.2)\n",
    "    fig, ax = plt.subplots(figsize=(12, fig_h))\n",
    "    y_map = {s: i for i, s in enumerate(sagas[::-1])}\n",
    "    colors = {'COMPLETED':'C0', 'FAILED':'C3', 'COMPENSATED':'C1', 'PENDING':'C4'}\n",
    "    for _, row in df_steps.iterrows():\n",
    "        y = y_map[row['saga_id']]\n",
    "        c = colors.get(row['status'], 'C7')\n",
    "        ax.barh(y, row['dur_s'], left=row['start_rel'], height=0.6, color=c, alpha=0.8)\n",
    "        ax.text(row['start_rel'] + 0.1, y, f\"{row['step_name']} ({row['service_name']})\", va='center', fontsize=8)\n",
    "\n",
    "    ax.set_yticks(list(y_map.values()))\n",
    "    ax.set_yticklabels(list(y_map.keys()))\n",
    "    ax.set_xlabel('seconds since first recorded step')\n",
    "    ax.set_title('Saga step timeline (bars = step duration) - color by step status')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No saga step logs found for timeline plot.\")\n",
    "# ...existing code...\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
