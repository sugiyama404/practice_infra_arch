{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40b4fd4",
   "metadata": {},
   "source": [
    "# Saga Pattern Performance Test Results Visualization\n",
    "\n",
    "このノートブックはSagaパターンの性能テスト結果を可視化します。\n",
    "\n",
    "## 前提条件\n",
    "\n",
    "以下のCSVファイルは `./saga_pattern/data` 配下の各パターン用サブディレクトリに配置してください：\n",
    "\n",
    "- `./saga_pattern/data/choreography_pattern/`\n",
    "  - `e2e_latency.csv`（E2Eレスポンス時間）\n",
    "  - `convergence_events.csv`（イベント収束）\n",
    "  - `saga_steps.csv`（サガステップ詳細）\n",
    "\n",
    "- `./saga_pattern/data/orchestration_pattern/`\n",
    "  - `e2e_latency.csv`\n",
    "  - `convergence_events.csv`\n",
    "  - `saga_steps.csv`\n",
    "  - `load_phase_results.csv`（ロードフェーズ結果）\n",
    "\n",
    "- `./saga_pattern/data/single_pessimistic_pattern/`\n",
    "  - `e2e_latency.csv`\n",
    "  - `convergence_events.csv`\n",
    "  - `saga_steps.csv`\n",
    "\n",
    "各CSVは列スキーマが共通であることを前提に、読み込み後に `pattern` 列で区別します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5541e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Resolve data directory relative to repo root or notebook location\n",
    "# Tries common roots to allow running from repo root or notebook folder\n",
    "\n",
    "def resolve_data_dir():\n",
    "    candidates = [\n",
    "        Path('./saga_pattern/data'),                               # from repo root\n",
    "        Path('../saga_pattern/data'),                              # from saga_pattern notebooks folder\n",
    "        Path(__file__).parent / 'data' if '__file__' in globals() else Path.cwd() / 'data'\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if (p / 'choreography_pattern').exists() and (p / 'orchestration_pattern').exists():\n",
    "            return p.resolve()\n",
    "    # Fallback to current working directory\n",
    "    return Path('./saga_pattern/data').resolve()\n",
    "\n",
    "DATA_DIR = resolve_data_dir()\n",
    "print(f\"データディレクトリ: {DATA_DIR}\")\n",
    "print(\"ライブラリの読み込み完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ecb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV data from pattern subdirectories\n",
    "print(\"=== CSVファイルの読み込み（3パターン統合）===\")\n",
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "pattern_dirs = {\n",
    "    'choreography': DATA_DIR / 'choreography_pattern',\n",
    "    'orchestration': DATA_DIR / 'orchestration_pattern',\n",
    "    'single_pessimistic': DATA_DIR / 'single_pessimistic_pattern',\n",
    "}\n",
    "\n",
    "# Initialize empty DataFrames\n",
    "cols_e2e = ['created_at', 'finished_at', 'e2e_ms']\n",
    "cols_conv = ['aggregate_id', 'processed_at']\n",
    "cols_saga = ['saga_id', 'step', 'status', 'is_compensation', 'started_at', 'completed_at', 'duration_ms']\n",
    "\n",
    "df_e2e_list: List[pd.DataFrame] = []\n",
    "df_conv_list: List[pd.DataFrame] = []\n",
    "df_saga_list: List[pd.DataFrame] = []\n",
    "\n",
    "for pattern, pdir in pattern_dirs.items():\n",
    "    try:\n",
    "        e2e_path = pdir / 'e2e_latency.csv'\n",
    "        conv_path = pdir / 'convergence_events.csv'\n",
    "        saga_path = pdir / 'saga_steps.csv'\n",
    "\n",
    "        if e2e_path.exists():\n",
    "            e2e = pd.read_csv(e2e_path, parse_dates=['created_at', 'finished_at'])\n",
    "            e2e['pattern'] = pattern\n",
    "            df_e2e_list.append(e2e)\n",
    "            print(f\"✓ E2E ({pattern}): {len(e2e)} rows\")\n",
    "        else:\n",
    "            print(f\"- E2E ファイルなし: {e2e_path}\")\n",
    "\n",
    "        if conv_path.exists():\n",
    "            conv = pd.read_csv(conv_path, parse_dates=['processed_at'])\n",
    "            conv['pattern'] = pattern\n",
    "            df_conv_list.append(conv)\n",
    "            print(f\"✓ Convergence ({pattern}): {len(conv)} rows\")\n",
    "        else:\n",
    "            print(f\"- Convergence ファイルなし: {conv_path}\")\n",
    "\n",
    "        if saga_path.exists():\n",
    "            saga = pd.read_csv(saga_path, parse_dates=['started_at', 'completed_at'])\n",
    "            saga['pattern'] = pattern\n",
    "            df_saga_list.append(saga)\n",
    "            print(f\"✓ Saga ({pattern}): {len(saga)} rows\")\n",
    "        else:\n",
    "            print(f\"- Saga ファイルなし: {saga_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"読み込みエラー ({pattern}): {e}\")\n",
    "\n",
    "# Concatenate\n",
    "if df_e2e_list:\n",
    "    df_e2e = pd.concat(df_e2e_list, ignore_index=True)\n",
    "else:\n",
    "    df_e2e = pd.DataFrame(columns=cols_e2e + ['pattern'])\n",
    "\n",
    "if df_conv_list:\n",
    "    df_conv = pd.concat(df_conv_list, ignore_index=True)\n",
    "else:\n",
    "    df_conv = pd.DataFrame(columns=cols_conv + ['pattern'])\n",
    "\n",
    "if df_saga_list:\n",
    "    df_saga = pd.concat(df_saga_list, ignore_index=True)\n",
    "else:\n",
    "    df_saga = pd.DataFrame(columns=cols_saga + ['pattern'])\n",
    "\n",
    "print(\"\\n=== データ概要 ===\")\n",
    "print(f\"E2E latency: {len(df_e2e)} rows, columns={list(df_e2e.columns)}\")\n",
    "print(f\"Convergence: {len(df_conv)} rows, columns={list(df_conv.columns)}\")\n",
    "print(f\"Saga steps: {len(df_saga)} rows, columns={list(df_saga.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de687a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of performance metrics\n",
    "def create_performance_graphs(df_e2e, df_conv, df_saga):\n",
    "    \"\"\"Create the 3 key performance graphs\"\"\"\n",
    "\n",
    "    if df_e2e.empty or df_conv.empty or df_saga.empty:\n",
    "        print(\"データが空のため、グラフを作成できません。CSVファイルを確認してください。\")\n",
    "        return\n",
    "\n",
    "    plt.style.use('default')\n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "\n",
    "    # 1. E2E Latency Distribution (p50/p95/p99)\n",
    "    plt.subplot(3, 2, 1)\n",
    "    if not df_e2e.empty and 'e2e_ms' in df_e2e.columns:\n",
    "        # Box plot by pattern\n",
    "        sns.boxplot(data=df_e2e, x='pattern', y='e2e_ms')\n",
    "        plt.title('E2E Latency Distribution by Pattern')\n",
    "        plt.ylabel('Latency (ms)')\n",
    "\n",
    "        # Add percentile lines\n",
    "        p50 = df_e2e['e2e_ms'].quantile(0.5)\n",
    "        p95 = df_e2e['e2e_ms'].quantile(0.95)\n",
    "        p99 = df_e2e['e2e_ms'].quantile(0.99)\n",
    "        plt.axhline(p50, color='green', linestyle='--', alpha=0.7, label=f'p50={p50:.0f}ms')\n",
    "        plt.axhline(p95, color='orange', linestyle='--', alpha=0.7, label=f'p95={p95:.0f}ms')\n",
    "        plt.axhline(p99, color='red', linestyle='--', alpha=0.7, label=f'p99={p99:.0f}ms')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No E2E latency data available', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('E2E Latency Distribution (No Data)')\n",
    "\n",
    "    # 2. E2E Latency Histogram\n",
    "    plt.subplot(3, 2, 2)\n",
    "    if not df_e2e.empty and 'e2e_ms' in df_e2e.columns:\n",
    "        plt.hist(df_e2e['e2e_ms'], bins=30, alpha=0.7, edgecolor='black')\n",
    "        plt.title('E2E Latency Histogram')\n",
    "        plt.xlabel('Latency (ms)')\n",
    "        plt.ylabel('Frequency')\n",
    "\n",
    "        # Add percentile markers\n",
    "        p50 = df_e2e['e2e_ms'].quantile(0.5)\n",
    "        p95 = df_e2e['e2e_ms'].quantile(0.95)\n",
    "        plt.axvline(p50, color='green', linestyle='--', label=f'p50={p50:.0f}ms')\n",
    "        plt.axvline(p95, color='orange', linestyle='--', label=f'p95={p95:.0f}ms')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No histogram data available', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('E2E Latency Histogram (No Data)')\n",
    "\n",
    "    # 3. Convergence Time Histogram\n",
    "    plt.subplot(3, 2, 3)\n",
    "    if not df_conv.empty:\n",
    "        # Calculate convergence time per aggregate\n",
    "        conv_summary = df_conv.groupby('aggregate_id').agg({\n",
    "            'processed_at': ['min', 'max', 'count']\n",
    "        }).reset_index()\n",
    "        conv_summary.columns = ['aggregate_id', 'first_event', 'last_event', 'event_count']\n",
    "        conv_summary['convergence_s'] = (\n",
    "            conv_summary['last_event'] - conv_summary['first_event']\n",
    "        ).dt.total_seconds()\n",
    "\n",
    "        if len(conv_summary) > 0:\n",
    "            plt.hist(conv_summary['convergence_s'], bins=20, alpha=0.7, edgecolor='black')\n",
    "            plt.title('Event Convergence Time Histogram')\n",
    "            plt.xlabel('Convergence Time (seconds)')\n",
    "            plt.ylabel('Frequency')\n",
    "\n",
    "            avg_conv = conv_summary['convergence_s'].mean()\n",
    "            plt.axvline(avg_conv, color='red', linestyle='--', label=f'Avg={avg_conv:.1f}s')\n",
    "            plt.legend()\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, 'No convergence data', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "            plt.title('Event Convergence (No Data)')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No convergence data available', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Event Convergence (No Data)')\n",
    "\n",
    "    # 4. Compensation Rate and Status\n",
    "    plt.subplot(3, 2, 4)\n",
    "    if not df_saga.empty and 'is_compensation' in df_saga.columns:\n",
    "        # Compensation rate by status\n",
    "        comp_summary = df_saga.groupby(['status', 'is_compensation']).size().unstack(fill_value=0)\n",
    "        comp_summary.plot(kind='bar', stacked=True, ax=plt.gca())\n",
    "        plt.title('Saga Steps: Normal vs Compensation')\n",
    "        plt.xlabel('Step Status')\n",
    "        plt.ylabel('Count')\n",
    "        plt.legend(['Normal', 'Compensation'])\n",
    "        plt.xticks(rotation=45)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No saga step data available', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Saga Steps (No Data)')\n",
    "\n",
    "    # 5. Saga Timeline (Sample)\n",
    "    plt.subplot(3, 2, 5)\n",
    "    if not df_saga.empty and len(df_saga) > 0:\n",
    "        # Show timeline for first few sagas\n",
    "        sample_sagas = df_saga['saga_id'].unique()[:5]  # First 5 sagas\n",
    "        saga_sample = df_saga[df_saga['saga_id'].isin(sample_sagas)].copy()\n",
    "\n",
    "        if not saga_sample.empty and 'started_at' in saga_sample.columns:\n",
    "            # Convert to relative time\n",
    "            base_time = saga_sample['started_at'].min()\n",
    "            saga_sample['start_rel'] = (saga_sample['started_at'] - base_time).dt.total_seconds()\n",
    "\n",
    "            # Derive duration seconds whether or not duration_ms exists\n",
    "            if 'duration_ms' in saga_sample.columns:\n",
    "                saga_sample['duration_s'] = saga_sample['duration_ms'] / 1000.0\n",
    "            elif 'completed_at' in saga_sample.columns:\n",
    "                saga_sample['duration_s'] = (saga_sample['completed_at'] - saga_sample['started_at']).dt.total_seconds().clip(lower=0)\n",
    "            else:\n",
    "                plt.text(0.5, 0.5, 'Insufficient duration data', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "                plt.title('Saga Timeline (Insufficient Data)')\n",
    "                plt.xlabel('Time (seconds from start)')\n",
    "                plt.yticks([])\n",
    "                plt.box(False)\n",
    "                plt.tight_layout()\n",
    "                # Early return from this subplot branch\n",
    "                pass\n",
    "\n",
    "            # Create Gantt-style chart\n",
    "            colors = {'COMPLETED': 'green', 'FAILED': 'red', 'COMPENSATED': 'orange', 'PENDING': 'blue'}\n",
    "\n",
    "            for i, saga_id in enumerate(sample_sagas):\n",
    "                saga_steps = saga_sample[saga_sample['saga_id'] == saga_id]\n",
    "                for _, step in saga_steps.iterrows():\n",
    "                    color = colors.get(step.get('status', ''), 'gray')\n",
    "                    alpha = 0.8 if bool(step.get('is_compensation', False)) else 0.6\n",
    "                    left = float(step.get('start_rel', 0))\n",
    "                    width = float(step.get('duration_s', 0))\n",
    "                    if width > 0:\n",
    "                        plt.barh(i, width, left=left, height=0.6, color=color, alpha=alpha)\n",
    "\n",
    "            plt.yticks(range(len(sample_sagas)), [f\"Saga {i+1}\" for i in range(len(sample_sagas))])\n",
    "            plt.xlabel('Time (seconds from start)')\n",
    "            plt.title('Sample Saga Timeline (Compensation in darker colors)')\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, 'Insufficient timeline data', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "            plt.title('Saga Timeline (Insufficient Data)')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No saga timeline data available', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Saga Timeline (No Data)')\n",
    "\n",
    "    # 6. Summary Statistics\n",
    "    plt.subplot(3, 2, 6)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Create summary text\n",
    "    summary_text = \"Performance Test Summary\\n\\n\"\n",
    "\n",
    "    if not df_e2e.empty:\n",
    "        summary_text += f\"E2E Latency (n={len(df_e2e)}):  \\n\"\n",
    "        summary_text += f\"  p50: {df_e2e['e2e_ms'].quantile(0.5):.1f}ms\\n\"\n",
    "        summary_text += f\"  p95: {df_e2e['e2e_ms'].quantile(0.95):.1f}ms\\n\"\n",
    "        summary_text += f\"  p99: {df_e2e['e2e_ms'].quantile(0.99):.1f}ms\\n\\n\"\n",
    "\n",
    "    if not df_conv.empty:\n",
    "        conv_summary = df_conv.groupby('aggregate_id').agg({\n",
    "            'processed_at': ['min', 'max']\n",
    "        }).reset_index()\n",
    "        conv_summary.columns = ['aggregate_id', 'first_event', 'last_event']\n",
    "        conv_summary['convergence_s'] = (conv_summary['last_event'] - conv_summary['first_event']).dt.total_seconds()\n",
    "\n",
    "        summary_text += f\"Convergence (n={len(conv_summary)}):  \\n\"\n",
    "        summary_text += f\"  Avg: {conv_summary['convergence_s'].mean():.2f}s\\n\"\n",
    "        summary_text += f\"  p95: {conv_summary['convergence_s'].quantile(0.95):.2f}s\\n\\n\"\n",
    "\n",
    "    if not df_saga.empty and 'is_compensation' in df_saga.columns:\n",
    "        comp_rate = df_saga['is_compensation'].mean() * 100\n",
    "        summary_text += f\"Saga Steps (n={len(df_saga)}):  \\n\"\n",
    "        summary_text += f\"  Compensation rate: {comp_rate:.1f}%\\n\"\n",
    "        summary_text += f\"  Total compensations: {df_saga['is_compensation'].sum()}\\n\"\n",
    "\n",
    "    plt.text(0.1, 0.9, summary_text, fontsize=10, verticalalignment='top',\n",
    "             transform=plt.gca().transAxes, family='monospace')\n",
    "    plt.title('Summary Statistics')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create performance graphs\n",
    "print(\"=== パフォーマンス可視化 ===\")\n",
    "create_performance_graphs(df_e2e, df_conv, df_saga)\n",
    "\n",
    "print(\"\\n=== 可視化完了 ===\")\n",
    "print(\"グラフは以下の内容を示しています:\")\n",
    "print(\"1. E2E latency distribution (低レイテンシー)\")\n",
    "print(\"2. Event convergence times (結果整合性)\")\n",
    "print(\"3. Compensation timeline (障害処理)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d25c4",
   "metadata": {},
   "source": [
    "## グラフの説明\n",
    "\n",
    "### 1. E2E Latency Distribution\n",
    "- **目的**: Sagaパターンの低レイテンシー特性を示す\n",
    "- **左上**: パターン別（Choreography vs Orchestration）のレイテンシー分布\n",
    "- **右上**: 全体のレイテンシーヒストグラム（p50/p95線付き）\n",
    "\n",
    "### 2. Event Convergence Time\n",
    "- **目的**: 結果整合性（Eventual Consistency）の収束時間を示す\n",
    "- **左中**: イベント発行から最終状態反映までの時間分布\n",
    "- **意味**: 数秒以内に収束すれば良好\n",
    "\n",
    "### 3. Saga Timeline & Compensation\n",
    "- **目的**: 補償処理の動作を可視化\n",
    "- **右中**: サガステップ（正常 vs 補償）の件数\n",
    "- **左下**: サンプルサガのタイムライン（補償ステップは濃い色）\n",
    "- **右下**: 統計サマリー\n",
    "\n",
    "## 重要指標\n",
    "\n",
    "- **低レイテンシー**: p95 < 1000ms が目安\n",
    "- **収束時間**: 平均 < 10秒 が目安  \n",
    "- **補償率**: 5-15% が一般的（失敗注入率に依存）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431eb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load phase-specific analysis (if available)\n",
    "def load_phase_analysis():\n",
    "    \"\"\"Load and analyze phase-specific load test results\"\"\"\n",
    "    print(\"=== Load Phase Analysis ===\")\n",
    "\n",
    "    try:\n",
    "        # phase results are only produced for orchestration in current setup\n",
    "        phase_path = DATA_DIR / 'orchestration_pattern' / 'load_phase_results.csv'\n",
    "        df_phases = pd.read_csv(phase_path, parse_dates=['timestamp'])\n",
    "        print(f\"✓ Load phase data: {len(df_phases)} rows from {phase_path}\")\n",
    "\n",
    "        # Phase comparison visualization\n",
    "        plt.figure(figsize=(15, 10))\n",
    "\n",
    "        # 1. Response time by phase (box plot)\n",
    "        plt.subplot(2, 3, 1)\n",
    "        sns.boxplot(data=df_phases, x='load_phase', y='response_time', order=['light', 'medium', 'heavy'])\n",
    "        plt.title('Response Time by Load Phase')\n",
    "        plt.ylabel('Response Time (s)')\n",
    "\n",
    "        # 2. Success rate by phase\n",
    "        plt.subplot(2, 3, 2)\n",
    "        success_by_phase = df_phases.groupby('load_phase')['status_code'].apply(\n",
    "            lambda x: (x.isin([200, 201])).mean() * 100\n",
    "        ).reindex(['light', 'medium', 'heavy'])\n",
    "        success_by_phase.plot(kind='bar')\n",
    "        plt.title('Success Rate by Load Phase')\n",
    "        plt.ylabel('Success Rate (%)')\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        # 3. Request count by phase\n",
    "        plt.subplot(2, 3, 3)\n",
    "        count_by_phase = df_phases['load_phase'].value_counts().reindex(['light', 'medium', 'heavy'])\n",
    "        count_by_phase.plot(kind='bar', color=['lightblue', 'orange', 'red'])\n",
    "        plt.title('Request Count by Load Phase')\n",
    "        plt.ylabel('Request Count')\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        # 4. Response time over time (timeline)\n",
    "        plt.subplot(2, 3, 4)\n",
    "        df_phases['timestamp_dt'] = pd.to_datetime(df_phases['timestamp'])\n",
    "        for phase in ['light', 'medium', 'heavy']:\n",
    "            phase_data = df_phases[df_phases['load_phase'] == phase]\n",
    "            if not phase_data.empty:\n",
    "                plt.scatter(phase_data['timestamp_dt'], phase_data['response_time'],\n",
    "                           label=phase, alpha=0.6, s=20)\n",
    "        plt.title('Response Time Timeline by Phase')\n",
    "        plt.ylabel('Response Time (s)')\n",
    "        plt.xlabel('Time')\n",
    "        plt.legend()\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        # 5. P95/P99 comparison across phases\n",
    "        plt.subplot(2, 3, 5)\n",
    "        percentiles = df_phases.groupby('load_phase')['response_time'].agg([\n",
    "            lambda x: x.quantile(0.50),\n",
    "            lambda x: x.quantile(0.95),\n",
    "            lambda x: x.quantile(0.99)\n",
    "        ]).reindex(['light', 'medium', 'heavy'])\n",
    "        percentiles.columns = ['P50', 'P95', 'P99']\n",
    "        percentiles.plot(kind='bar')\n",
    "        plt.title('Response Time Percentiles by Phase')\n",
    "        plt.ylabel('Response Time (s)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "\n",
    "        # 6. Pattern distribution by phase\n",
    "        plt.subplot(2, 3, 6)\n",
    "        if 'pattern' in df_phases.columns:\n",
    "            pattern_phase = pd.crosstab(df_phases['load_phase'], df_phases['pattern'], normalize='index') * 100\n",
    "            pattern_phase.reindex(['light', 'medium', 'heavy']).plot(kind='bar', stacked=True)\n",
    "            plt.title('Pattern Distribution by Phase (%)')\n",
    "            plt.ylabel('Percentage')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.legend()\n",
    "        else:\n",
    "            plt.axis('off')\n",
    "            plt.text(0.1, 0.8, 'No pattern breakdown in phase dataset', transform=plt.gca().transAxes)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Summary statistics\n",
    "        print(\"\\n=== Phase Summary Statistics ===\")\n",
    "        phase_stats = df_phases.groupby('load_phase').agg({\n",
    "            'response_time': ['count', 'mean', 'std', lambda x: x.quantile(0.95), lambda x: x.quantile(0.99)],\n",
    "            'status_code': lambda x: (x.isin([200, 201])).mean() * 100\n",
    "        }).round(3)\n",
    "        phase_stats.columns = ['Count', 'Avg_RT(s)', 'Std_RT', 'P95_RT(s)', 'P99_RT(s)', 'Success_Rate(%)']\n",
    "        print(phase_stats.reindex(['light', 'medium', 'heavy']))\n",
    "\n",
    "        return df_phases\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"load_phase_results.csv not found under orchestration_pattern. Multi-phase test may not have been run.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading phase data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run phase analysis\n",
    "df_phase_results = load_phase_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
