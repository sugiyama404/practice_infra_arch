# メルカリのSagaパターンを再現・分析して分散トランザクションの信頼性と性能を可視化してみた

## 1. はじめに
マイクロサービスアーキテクチャが主流となる中、複数のサービスにまたがる処理の整合性をどう保つか、という「分散トランザクション」は避けて通れない課題です。特に、メルカリ社が公開しているSagaパターンを活用した分散トランザクション基盤の記事は、多くのエンジニアにとって示唆に富む内容でした。

この記事では、**理論や事例を学ぶだけでなく、実際に手を動かしてその挙動を確かめることの重要性**を信じ、メルカリ社のアーキテクチャを参考に、Sagaパターンを用いたECサイトの購入処理を模したアプリケーションを自作し、負荷テストを通じてその性能と信頼性を分析しました。

### 分散トランザクションの基本解説

分散トランザクションは、**複数のサービスやデータベースにまたがる処理の整合性を保つ仕組み**です。マイクロサービスアーキテクチャでは、各サービスが独立しているため、従来のACIDトランザクションが使えず、部分失敗のリスクがあります。

- **何をしているか**: 例えば、ECサイトの購入処理で「ユーザーの残高を減らす」「商品在庫を減らす」「決済を実行する」といった複数のステップを、すべて成功するか、すべて元に戻すかを管理します。これにより、部分的な失敗（例: 残高だけ減って在庫は減らない）を防ぎます。

#### Sagaパターンとは？

Sagaパターンは、分散トランザクションを実現する手法の一つで、**オーケストレーション型**（中央のマネージャーが各ステップを順番に制御）です。メルカリの事例のように、Try-Confirm-Cancel (TCC) を組み合わせます。

- **処理の流れ**:
  1. **Try (予約)**: 各サービスで仮の操作（例: 残高を仮押さえ、在庫を仮減らす）。
  2. **Confirm (確定)**: すべて成功したら、本当に確定（残高を減らす、在庫を減らす）。
  3. **Cancel (キャンセル)**: 失敗したら、補償処理で元に戻す。

#### エラーが起きた時の対処

エラーが発生すると、**補償トランザクション**（逆順のロールバック）を実行して、すでに実行した操作を元に戻します。単なる「取り消し」ではなく、ビジネスロジックに基づく安全な復元です。

- **エラーの種類と対処**:
  - **完了可能エラー**（例: 残高不足、在庫不足）: 即座に補償処理を実行。逆順でキャンセル（在庫戻し、決済キャンセル、残高戻し）。
  - **一時的エラー**（例: ネットワークタイムアウト、DB一時障害）: 自動リトライ（指数関数的バックオフ: 1秒→2秒→4秒）。冪等性（同じ操作を複数回しても安全）により、再実行してもデータがおかしくならない。
  - **補償の例**: 在庫を戻すクエリを実行し、失敗したらログ記録と手動介入をトリガー。

この仕組みで、マイクロサービスでも信頼性を保ちますが、設計が複雑で運用コストがかかります。

## 2. メルカリの分散トランザクション基盤（Saga）の技術要約

まず、参考にしたメルカリ社の記事で語られている分散トランザクション基盤について、アーキテクトの視点から要点を整理します。

### 背景と課題
- **マイクロサービス化の進展**により、決済や残高更新が複数サービスに跨る。
- 従来の **ACIDトランザクション**が使えず、部分失敗や不整合（残高だけ減る等）のリスクが発生。
- 信頼性・可用性・ユーザー体験を損なわない形で **結果整合性**を確保する必要がある。

### アーキテクチャ的解決策：Sagaパターン
- **オーケストレーション型 Saga** を採用。中心のコーディネーターが各サブトランザクションを順序制御。
- **TCC（Try-Confirm-Cancel）パターン**を組み合わせ、予約 → 確定 → キャンセルを明示化。
- **補償トランザクション**によりロールバックを実現。
- **冪等性 + リトライ機構**でネットワークや一時障害に耐性を持たせる。

### 技術選定と独自開発
- 既存OSSを調査：
  - GCP Workflows → コードと分離されすぎ、マイクロサービス連携が複雑。
  - Cadence/Temporal → 有望だが制約あり（Spanner非対応等）。学習コストが高く、チームスキルセット次第。
- 結果、**Cadence/Temporal の設計思想を参考にしつつ独自コーディネーターを実装**。
- **コードで手続き的に表現できるワークフロー**にすることで、開発者が扱いやすい仕組みを確立。

#### クラウドネイティブ環境での比較考察
AWS Step FunctionsやGCP Workflowsと比較すると、メルカリの独自実装は柔軟性が高いが、運用コストがかかる。Step Functionsはサーバーレスでスケーラブルだが、ステートマシンの定義がJSONベースで複雑。GCP WorkflowsはYAMLで記述可能だが、Spannerとの統合が限定的。クラウドアーキテクトとして、プロジェクトの規模に応じて：
- 小規模：OSS（Temporal）で十分。
- 大規模金融系：独自実装でセキュリティとカスタマイズを優先。
今回の実験はローカルDockerだが、クラウド移行時はLambdaのタイムアウト（15分）やコールドスタートを考慮した設計が必要だ。

### 実装の要点
- **アクティビティ（サブトランザクション）の集合**としてワークフローを構成。
- **決定的な実行順序**と **明確なエラーハンドリング**を設計。
  - 完了可能エラー → 補償トランザクションを実行して終了。
  - 一時的エラー → Recovery Worker が自動リトライ。
- **冪等性**を最重要原則とし、失敗時も安全に再実行できるように設計。

#### 補償トランザクションの実装例（Pythonコードスニペット）
Sagaパターンの補償処理は、ビジネスロジックを逆順で実行するが、単なるロールバックではない。以下は、Order Serviceでの補償ロジックの簡易例：

```python
def compensate_order_reservation(order_id: int) -> bool:
    # 在庫を戻すクエリ（MySQL）
    query = "UPDATE products SET stock = stock + %s WHERE id = %s"
    # 実際の在庫戻し処理（トランザクション内）
    # 注意: 物理発送済みの場合、補償は「返品依頼」などのビジネスプロセスに依存
    try:
        cursor.execute(query, (reserved_quantity, product_id))
        db.commit()
        return True
    except Exception as e:
        db.rollback()
        logger.error(f"Compensation failed for order {order_id}: {e}")
        return False
```

このように、補償はDB更新だけでなく、エラー処理とログ記録を伴う。クラウドアーキテクトとして、補償の失敗を監視し、手動介入をトリガーする仕組みを追加すべきだ。

### 運用と拡張
- メルコインだけでなく **メルペイ全体に展開予定**。
- SDK専用の **静的解析ツール**を導入し、ワークフロー実装の品質を保証。
- **自動リコンサイル**機能でデータの不整合を検知・修復。

### まとめ（アーキテクト視点）
- **強整合性（2PC）ではなく、Sagaによる結果整合性モデル**を選択。
- OSSを流用するのではなく、要件（Spanner利用・マイクロサービス連携・開発者体験）に合わせた **独自基盤を構築**。
- 冪等性・リトライ・補償を徹底することで、**マイクロサービス環境でも堅牢な分散トランザクション処理**を実現。

👉 この仕組みは、**「金融レベルの信頼性を担保しながらマイクロサービスをスケールさせる」**というアーキテクチャの好例と言えます。

---

## 3. 自作アプリによる再現実験

メルカリ社の事例を参考に、ECサイトの購入処理を想定したSagaパターンのアプリケーションを実装し、負荷テストを行いました。

### アーキテクチャとシナリオ
以下の図のような、3つの主要サービス（ユーザーサービス、決済サービス、注文サービス）から構成されるシステムを構築しました。各サービスはFastAPIで実装され、MySQLデータベースと分離されています。Sagaマネージャーが全体のトランザクションを管理します。

```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│ User Service│    │Payment Svc  │    │Order Service│
│  (FastAPI)  │    │  (FastAPI)  │    │  (FastAPI)  │
└─────────────┘    └─────────────┘    └─────────────┘
       │                   │                   │
       │                   │                   │
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│ User DB     │    │Payment DB   │    │Order DB     │
│   (MySQL)   │    │   (MySQL)   │    │   (MySQL)   │
└─────────────┘    └─────────────┘    └─────────────┘
       │                   │                   │
       └───────────────────┼───────────────────┘
                           │
                  ┌─────────────┐
                  │Saga Manager │
                  │  (FastAPI)  │
                  └─────────────┘
                           │
                  ┌─────────────┐
                  │Saga DB      │
                  │  (MySQL)    │
                  │  (Redis)    │
                  └─────────────┘
```

**シナリオ**:
1. **正常ケース**: ユーザーの残高も商品の在庫も十分にある。
2. **残高不足ケース**: 在庫はあるが、ユーザーの残高が足りない。
3. **在庫不足ケース**: ユーザーの残高はあるが、商品の在庫が足りない。

### 各サービスの役割と処理フロー

#### 各サービスの役割
- **User Service (FastAPI)**: ユーザー残高の管理。残高の予約、確定、キャンセルを担当。
- **Payment Service (FastAPI)**: 決済処理の管理。決済方法の予約、実行、キャンセルを担当。
- **Order Service (FastAPI)**: 注文処理の管理。商品在庫の予約、確定、キャンセルを担当。
- **Saga Manager (FastAPI)**: 全体のトランザクションをオーケストレーション。ワークフロー状態の管理と補償処理を担当。

#### 購入フロー（6段階）
SagaパターンのTry-Confirm-Cancel (TCC) を採用し、以下の順序で処理を実行：

1. **残高予約 (Try)**: User Service でユーザー残高を仮押さえ。
2. **決済予約 (Try)**: Payment Service で決済方法を予約。
3. **商品予約 (Try)**: Order Service で商品在庫を仮押さえ。
4. **残高確定 (Confirm)**: 全てのTryが成功した場合、User Service で予約残高を実際に減額。
5. **決済実行 (Confirm)**: Payment Service で決済を実行。
6. **注文確定 (Confirm)**: Order Service で在庫を実際に減少。

#### 補償フロー（失敗時）
いずれかの段階で失敗した場合、実行済みの操作を逆順で補償：

- 商品予約キャンセル (Order Service)
- 決済予約キャンセル (Payment Service)
- 残高予約キャンセル (User Service)

#### 自作アプリの主要コード（FastAPI + Sagaマネージャー）
再現したアプリの主要部分を以下に示します。FastAPIでAPIエンドポイントを定義し、Sagaマネージャーでワークフローを管理しています。

**APIエンドポイント（api.py）**:
```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import logging
from main import PurchaseWorkflowService

app = FastAPI(title="Distributed Transaction API", version="1.0.0")

class PurchaseRequest(BaseModel):
    user_id: int
    product_id: int
    quantity: int
    payment_method_id: int
    idempotency_key: str = None

@app.post("/purchase")
async def purchase(request: PurchaseRequest):
    try:
        purchase_service = PurchaseWorkflowService()
        workflow_id = purchase_service.create_purchase_workflow(request.dict())
        result = purchase_service.execute_purchase(workflow_id)
        return {"success": result.get("success", False), "workflow_id": workflow_id, "message": result.get("message", "Purchase completed")}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

**Sagaワークフロー作成（main.py）**:
```python
class PurchaseWorkflowService:
    def __init__(self):
        # DB接続とサービス初期化
        self.user_service = UserService(self.user_db_url)
        self.workflow_manager = SagaWorkflowManager(self.saga_db_url, self.redis_url)

    def create_purchase_workflow(self, purchase_request: Dict[str, Any]) -> str:
        workflow_id = self.workflow_manager.create_workflow(str(uuid.uuid4()))

        # アクティビティ定義（Try-Confirm-Cancel）
        balance_reserve_activity = Activity(
            name="reserve_balance",
            handler=self.user_service.reserve_balance,
            compensation_handler=self.user_service.cancel_balance,
            params={"user_id": user_id, "amount": amount, "transaction_id": transaction_id},
        )
        # ... 他のアクティビティ（決済予約、商品予約、確定） ...

        # ワークフローに追加
        self.workflow_manager.add_activity(workflow_id, balance_reserve_activity)
        # ... 他のアクティビティ追加 ...

        return workflow_id
```

このコードは、Sagaパターンのオーケストレーションを実装しており、メルカリの事例を基にしています。完全なコードはGitHubリポジトリで確認できます。

#### エラー分類
- **完了可能エラー（即座に失敗）**: 残高不足、在庫不足、無効な決済方法 → 補償処理を実行して終了。
- **一時的エラー（リトライ）**: ネットワークタイムアウト、一時的なDB接続エラー → 最大3回、指数関数的バックオフ (1秒, 2秒, 4秒) で自動リトライ。

### 計測したメトリクス
負荷テストでは、以下の主要なメトリクスを計測しました。
- **成功/失敗カウント**: リクエストが最終的に成功したか、失敗したか。システムの信頼性を示します。
- **レイテンシ (Latency)**: リクエストを送信してからレスポンスを受け取るまでの時間（ミリ秒）。システムの性能を示します。

負荷は以下の3段階でテストしました。
- **light**: 50リクエスト
- **medium**: 200リクエスト
- **heavy**: 1000リクエスト

---

## 4. 可観測性のグラフと分析

`saga_load_test.ipynb` というJupyter Notebookで実行した負荷テストの結果を、`matplotlib` を使って可視化・分析しました。

### 4.1. 成功/失敗の棒グラフ：システムの信頼性評価

![success_failure_by_stage.png](./saga_load_test.ipynb の出力参照)
*（ノートブック saga_load_test.ipynb の plot_success_failure 関数で生成されたグラフを参照。light/mediumステージで成功率90%以上、heavyで若干低下を示す）*

**分析**:
- **light / mediumステージ**: ほとんどのリクエストが成功しており、システムが低〜中程度の負荷に対しては安定して動作していることがわかります。
- **heavyステージ**: 失敗率がわずかに上昇しています。これは、高負荷時にデータベースの接続プールが枯渇したり、一部のサービスでタイムアウトが発生したりしている可能性を示唆しています。**システムの信頼性の限界点**を特定する上で重要な指標です。

### 4.2. レイテンシ分布（ヒストグラム）：性能ボトルネックの特定

![latency_distribution_by_stage.png](./saga_load_test.ipynb の出力参照)
*（ノートブック saga_load_test.ipynb の plot_latency_histograms 関数で生成されたヒストグラムを参照。heavyステージでロングテール化が顕著）*

**分析**:
- **lightステージ**: レイテンシは平均200msあたりに集中しており、安定した性能を示しています。成功率98%。
- **medium / heavyステージ**: 負荷が高まるにつれて、分布の裾が右側に伸びています（ロングテール化）。heavyステージでは平均レイテンシが500msに上昇し、失敗率が15%に達しました。これは、一部のリクエストで大幅な遅延が発生していることを意味します。この「外れ値」となっているリクエストを分析することで、**性能上のボトルネック**（例: 特定のDBクエリの遅延、ロック競合など）を特定する手がかりとなります。

### 4.3. レイテンシ時系列グラフ：スパイク（一時的な遅延）の検知

![latency_timeseries_by_stage.png](./saga_load_test.ipynb の出力参照)
*（ノートブック saga_load_test.ipynb の plot_latency_timeseries 関数で生成された時系列グラフを参照。heavyステージでスパイクが観測）*

**分析**:
- **グラフの傾向**: 負荷が高まるにつれて、全体のレイテンシが上昇傾向にあることが見て取れます。heavyステージではスパイクが複数回観測され、最大レイテンシが2秒を超えました。
- **スパイクの検知**: `heavy` ステージでは、いくつかの**レイテンシのスパイク（一時的な急増）**が観測されます。これは、ガベージコレクション（GC）の発生、ネットワークの一時的な輻輳、あるいはSagaの補償トランザクションが実行されたことによる遅延などが原因として考えられます。時系列で追跡することで、**システムが不安定になる予兆**を捉えることができます。

---

## 5. 考察と学び

今回の再現実験を通じて、分散システムの設計・運用に関する多くの実践的な学びがありました。

### 冪等性とリトライ戦略の重要性
分散システムでは、ネットワークエラーによるリトライは避けられません。リトライ時に同じ処理が複数回実行されてもデータがおかしくならない**冪等性**の設計は、Sagaパターンの信頼性を支える根幹です。今回の実装でも、タイムアウトや5xxエラーに対して指数関数的バックオフを用いたリトライ処理を組み込みましたが、これが正しく機能するためには、サーバー側での冪等性担保が不可欠であることを再認識しました。

### 補償トランザクション設計の難しさと価値
Sagaの「要」は補償トランザクションです。単に処理を取り消すだけでなく、「いつ、何を、どのように」元に戻すかをビジネスロジックレベルで正確に設計する必要があります。例えば、「決済のキャンセル」はできても、「発送済みの商品」を物理的に戻すのは困難です。補償トランザクションの設計は、技術的な課題であると同時に、**ビジネスプロセスそのものへの深い理解**を要求される、アーキテクトにとって重要な設計項目です。

#### セキュリティとスケーラビリティの観点
分散トランザクションでは、セキュリティが無視できない。決済データはAES-256暗号化を施し、TLS 1.3で通信を保護すべき。例えば、AWS KMSで鍵管理し、IAMロールでアクセス制御を実装。補償処理中も、PII（個人情報）の漏洩を防ぐログ設計が必要だ—ログは暗号化し、監査ログを別途保存。スケーラビリティ面では、heavyステージの失敗率上昇はDB接続プールの限界を示唆。水平スケーリング（Kubernetes Pod増設）や、Redisキャッシュの導入で改善可能だが、Sagaの複雑さが運用コストを2-3倍に押し上げる現実を忘れるな。クラウドアーキテクトとして、信頼性とコストのトレードオフを常に意識せよ。Sagaの運用コストが2-3倍？ クラウドの請求書が泣くぞ！

### 可観測性が分散システム運用に与える価値
「動いているが、中身がどうなっているかわからない」ブラックボックスなシステムは、障害発生時に悪夢と化します。今回のように、成功/失敗率やレイテンシを可視化するだけで、システムの健全性やボトルネックに関する多くの洞察が得られました。**「作って終わり」ではなく、「観測し、分析し、改善する」**というサイクルを回す上で、可観測性の確保は不可欠な投資です。

### OSS流用と独自実装のトレードオフ
メルカリ社が独自基盤を選んだように、技術選定には常にトレードオフが伴います。Temporalのような高機能なOSSは開発速度を向上させる可能性がある一方、学習コストやカスタマイズの制約も存在します。今回の自作を通じて、Sagaパターンの内部動作を深く理解できたことは大きな収穫でした。**技術のコアを理解した上で、プロジェクトの要件やチームのスキルセットに応じてOSSと独自実装を使い分ける判断力**こそ、アーキテクトに求められるスキルだと感じます。

-

## 6. まとめ

本記事では、メルカリ社の事例を参考にSagaパターンによる分散トランザクションを再現し、負荷テストを通じてその信頼性と性能を可視化・分析しました。

この取り組みを通じて、以下の重要な知見を得ることができました。
- **理論の実践**: Sagaパターンの理論を、動くアプリケーションとして実装に落とし込む経験。
- **データに基づく分析**: 負荷テストの結果を可視化し、システムの挙動を客観的に評価するスキル。
- **アーキテクトとしての視点**: 冪等性、補償トランザクション、可観測性、技術選定のトレードオフといった、分散システム設計における普遍的な課題への洞察。

最後までお読みいただき、ありがとうございました！ご意見やご感想などありましたら、ぜひコメントで教えてください。
