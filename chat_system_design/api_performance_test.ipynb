{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eab55a7",
   "metadata": {},
   "source": [
    "# Chat System API Performance Test\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ã®APIã«å¯¾ã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã—ã¾ã™ã€‚\n",
    "ä»¥ä¸‹ã®åˆ†ææ‰‹æ³•ã‚’ç”¨ã„ã¦ã€ã‚·ã‚¹ãƒ†ãƒ ã®å®‰å®šæ€§ã¨æ€§èƒ½ã‚’è©•ä¾¡ã—ã¾ã™ï¼š\n",
    "\n",
    "1. **ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ vs ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·**: åŒæ™‚æ¥ç¶šæ•°ã«å¯¾ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®åˆ†æ\n",
    "2. **ç§’é–“ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†æ•°**: æ™‚é–“çµŒéã«ã‚ˆã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†æ€§èƒ½ã®å¯è¦–åŒ–\n",
    "3. **RabbitMQã‚­ãƒ¥ãƒ¼é•·ã®æ¨ç§»**: è² è·ä¸‹ã§ã®ã‚­ãƒ¥ãƒ¼çŠ¶æ…‹ã®ç›£è¦–\n",
    "\n",
    "## APIãƒ†ã‚¹ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "import pika  # RabbitMQ client\n",
    "from collections import defaultdict\n",
    "import statistics\n",
    "\n",
    "# APIè¨­å®š\n",
    "BASE_URL = \"http://localhost:8080\"\n",
    "WS_URL = \"ws://localhost:8080\"\n",
    "\n",
    "# RabbitMQè¨­å®š\n",
    "RABBITMQ_HOST = 'localhost'\n",
    "RABBITMQ_PORT = 5672\n",
    "RABBITMQ_USER = 'guest'\n",
    "RABBITMQ_PASS = 'guest'\n",
    "QUEUE_NAME = 'messages'  # ã‚­ãƒ¥ãƒ¼åã¯é©å®œèª¿æ•´\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "ROOM_ID = \"test_room\"\n",
    "USER_PREFIX = \"test_user_\"\n",
    "DEVICE_PREFIX = \"device_\"\n",
    "\n",
    "print(\"ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a4be41",
   "metadata": {},
   "source": [
    "## åŒæ™‚æ¥ç¶šæ•°ã«ã‚ˆã‚‹ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¸¬å®š\n",
    "\n",
    "åŒæ™‚æ¥ç¶šæ•°ã‚’å¤‰åŒ–ã•ã›ãªãŒã‚‰ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’æ¸¬å®šã—ã¾ã™ã€‚\n",
    "å„æ¥ç¶šæ•°ã§è¤‡æ•°å›ã®é€ä¿¡ã‚’è¡Œã„ã€p50/p95/p99ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã‚’è¨ˆç®—ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d508fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def send_message_async(session, user_id, device_id, room_id, content):\n",
    "    \"\"\"éåŒæœŸã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡\"\"\"\n",
    "    url = f\"{BASE_URL}/api/messages/send\"\n",
    "    data = {\n",
    "        \"user_id\": user_id,\n",
    "        \"device_id\": device_id,\n",
    "        \"room_id\": room_id,\n",
    "        \"content\": content,\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        async with session.post(url, json=data) as response:\n",
    "            await response.json()\n",
    "            latency = (time.time() - start_time) * 1000  # ms\n",
    "            return latency\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending message: {e}\")\n",
    "        return None\n",
    "\n",
    "async def measure_latency_for_concurrent_users(num_users, num_messages_per_user=10):\n",
    "    \"\"\"æŒ‡å®šã•ã‚ŒãŸåŒæ™‚æ¥ç¶šæ•°ã§ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¸¬å®š\"\"\"\n",
    "    latencies = []\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for user_idx in range(num_users):\n",
    "            user_id = f\"{USER_PREFIX}{user_idx}\"\n",
    "            device_id = f\"{DEVICE_PREFIX}{user_idx}\"\n",
    "\n",
    "            for msg_idx in range(num_messages_per_user):\n",
    "                content = f\"Test message {msg_idx} from user {user_idx}\"\n",
    "                task = send_message_async(session, user_id, device_id, ROOM_ID, content)\n",
    "                tasks.append(task)\n",
    "\n",
    "        # åŒæ™‚å®Ÿè¡Œ\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "        for result in results:\n",
    "            if isinstance(result, float):\n",
    "                latencies.append(result)\n",
    "\n",
    "    return latencies\n",
    "\n",
    "def calculate_percentiles(latencies):\n",
    "    \"\"\"ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®—\"\"\"\n",
    "    if not latencies:\n",
    "        return 0, 0, 0\n",
    "\n",
    "    sorted_latencies = sorted(latencies)\n",
    "    p50 = statistics.median(sorted_latencies)\n",
    "    p95 = np.percentile(sorted_latencies, 95)\n",
    "    p99 = np.percentile(sorted_latencies, 99)\n",
    "\n",
    "    return p50, p95, p99\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ\n",
    "concurrent_users_list = [1, 5, 10, 20, 50]\n",
    "latency_results = {}\n",
    "\n",
    "print(\"ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¸¬å®šã‚’é–‹å§‹...\")\n",
    "for num_users in concurrent_users_list:\n",
    "    print(f\"Testing with {num_users} concurrent users...\")\n",
    "    latencies = await measure_latency_for_concurrent_users(num_users)\n",
    "    p50, p95, p99 = calculate_percentiles(latencies)\n",
    "    latency_results[num_users] = {\n",
    "        'p50': p50,\n",
    "        'p95': p95,\n",
    "        'p99': p99,\n",
    "        'latencies': latencies\n",
    "    }\n",
    "    print(\".1f\")\n",
    "\n",
    "print(\"ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¸¬å®šå®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06be67b",
   "metadata": {},
   "source": [
    "## ç§’é–“ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†æ•°ã®æ¸¬å®š\n",
    "\n",
    "ãƒãƒ¼ã‚¹ãƒˆè² è·ã‚’ã‹ã‘ãªãŒã‚‰ã€1ç§’ã‚ãŸã‚Šã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†æ•°ã‚’æ¸¬å®šã—ã¾ã™ã€‚\n",
    "Workerã®å‡¦ç†æ€§èƒ½ã¨å®‰å®šæ€§ã‚’è©•ä¾¡ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563e55b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def burst_load_test(duration_sec=60, burst_users=100, messages_per_burst=50):\n",
    "    \"\"\"ãƒãƒ¼ã‚¹ãƒˆè² è·ãƒ†ã‚¹ãƒˆ\"\"\"\n",
    "    message_counts = defaultdict(int)\n",
    "    start_time = time.time()\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        while time.time() - start_time < duration_sec:\n",
    "            tasks = []\n",
    "            for user_idx in range(burst_users):\n",
    "                user_id = f\"{USER_PREFIX}burst_{user_idx}\"\n",
    "                device_id = f\"{DEVICE_PREFIX}burst_{user_idx}\"\n",
    "\n",
    "                for msg_idx in range(messages_per_burst):\n",
    "                    content = f\"Burst message {msg_idx}\"\n",
    "                    task = send_message_async(session, user_id, device_id, ROOM_ID, content)\n",
    "                    tasks.append(task)\n",
    "\n",
    "            # ãƒãƒ¼ã‚¹ãƒˆé€ä¿¡\n",
    "            await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "            # 1ç§’ã”ã¨ã®ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "            current_sec = int(time.time() - start_time)\n",
    "            message_counts[current_sec] += len(tasks)\n",
    "\n",
    "            await asyncio.sleep(1)  # 1ç§’å¾…æ©Ÿ\n",
    "\n",
    "    return dict(message_counts)\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ\n",
    "print(\"ãƒãƒ¼ã‚¹ãƒˆè² è·ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...\")\n",
    "message_rate_results = await burst_load_test(duration_sec=30, burst_users=20, messages_per_burst=10)\n",
    "print(\"ãƒãƒ¼ã‚¹ãƒˆè² è·ãƒ†ã‚¹ãƒˆå®Œäº†\")\n",
    "\n",
    "# çµæœè¡¨ç¤º\n",
    "total_messages = sum(message_rate_results.values())\n",
    "avg_rate = total_messages / len(message_rate_results) if message_rate_results else 0\n",
    "print(f\"ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {total_messages}\")\n",
    "print(\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b92f46",
   "metadata": {},
   "source": [
    "## RabbitMQã‚­ãƒ¥ãƒ¼é•·ã®ç›£è¦–\n",
    "\n",
    "ãƒ†ã‚¹ãƒˆä¸­ã®RabbitMQã‚­ãƒ¥ãƒ¼é•·ã‚’ç›£è¦–ã—ã€è² è·ä¸‹ã§ã®å‡¦ç†è¿½å¾“æ€§ã‚’è©•ä¾¡ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561cab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_queue_length():\n",
    "    \"\"\"RabbitMQã‚­ãƒ¥ãƒ¼é•·ã‚’å–å¾—\"\"\"\n",
    "    try:\n",
    "        credentials = pika.PlainCredentials(RABBITMQ_USER, RABBITMQ_PASS)\n",
    "        connection = pika.BlockingConnection(\n",
    "            pika.ConnectionParameters(RABBITMQ_HOST, RABBITMQ_PORT, '/', credentials)\n",
    "        )\n",
    "        channel = connection.channel()\n",
    "\n",
    "        # ã‚­ãƒ¥ãƒ¼æƒ…å ±ã‚’å–å¾—\n",
    "        queue_info = channel.queue_declare(queue=QUEUE_NAME, passive=True)\n",
    "        queue_length = queue_info.method.message_count\n",
    "\n",
    "        connection.close()\n",
    "        return queue_length\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting queue length: {e}\")\n",
    "        return 0\n",
    "\n",
    "async def monitor_queue_length(duration_sec=30, interval_sec=1):\n",
    "    \"\"\"ã‚­ãƒ¥ãƒ¼é•·ã‚’ç›£è¦–\"\"\"\n",
    "    queue_lengths = {}\n",
    "    start_time = time.time()\n",
    "\n",
    "    while time.time() - start_time < duration_sec:\n",
    "        current_sec = int(time.time() - start_time)\n",
    "        length = get_queue_length()\n",
    "        queue_lengths[current_sec] = length\n",
    "        print(f\"Time {current_sec}s: Queue length = {length}\")\n",
    "        await asyncio.sleep(interval_sec)\n",
    "\n",
    "    return queue_lengths\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆãƒãƒ¼ã‚¹ãƒˆãƒ†ã‚¹ãƒˆã¨ä¸¦è¡Œã—ã¦å®Ÿè¡Œï¼‰\n",
    "print(\"ã‚­ãƒ¥ãƒ¼é•·ç›£è¦–ã‚’é–‹å§‹...\")\n",
    "queue_length_results = await monitor_queue_length(duration_sec=30)\n",
    "print(\"ã‚­ãƒ¥ãƒ¼é•·ç›£è¦–å®Œäº†\")\n",
    "\n",
    "# çµæœè¡¨ç¤º\n",
    "max_queue_length = max(queue_length_results.values()) if queue_length_results else 0\n",
    "avg_queue_length = sum(queue_length_results.values()) / len(queue_length_results) if queue_length_results else 0\n",
    "print(f\"æœ€å¤§ã‚­ãƒ¥ãƒ¼é•·: {max_queue_length}\")\n",
    "print(\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b67252",
   "metadata": {},
   "source": [
    "## ã‚°ãƒ©ãƒ•ä½œæˆã¨çµæœã®ã¾ã¨ã‚\n",
    "\n",
    "æ¸¬å®šçµæœã‚’ã‚°ãƒ©ãƒ•ã§å¯è¦–åŒ–ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½ã‚’ã¾ã¨ã‚ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚°ãƒ©ãƒ•1: ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ vs ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "users = list(latency_results.keys())\n",
    "p50_latencies = [latency_results[u]['p50'] for u in users]\n",
    "p95_latencies = [latency_results[u]['p95'] for u in users]\n",
    "p99_latencies = [latency_results[u]['p99'] for u in users]\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(users, p50_latencies, 'o-', label='p50', color='blue')\n",
    "plt.plot(users, p95_latencies, 's-', label='p95', color='orange')\n",
    "plt.plot(users, p99_latencies, '^-', label='p99', color='red')\n",
    "plt.xlabel('åŒæ™‚æ¥ç¶šæ•°ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ï¼‰')\n",
    "plt.ylabel('ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms)')\n",
    "plt.title('ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ vs ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# ã‚°ãƒ©ãƒ•2: ç§’é–“ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†æ•°\n",
    "plt.subplot(2, 2, 2)\n",
    "times = list(message_rate_results.keys())\n",
    "rates = list(message_rate_results.values())\n",
    "plt.bar(times, rates, color='green', alpha=0.7)\n",
    "plt.xlabel('æ™‚é–“ (ç§’)')\n",
    "plt.ylabel('1ç§’ã‚ãŸã‚Šã®å‡¦ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•° (messages/sec)')\n",
    "plt.title('ç§’é–“ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†æ•°')\n",
    "plt.grid(True)\n",
    "\n",
    "# ã‚°ãƒ©ãƒ•3: RabbitMQã‚­ãƒ¥ãƒ¼é•·ã®æ¨ç§»\n",
    "plt.subplot(2, 2, 3)\n",
    "queue_times = list(queue_length_results.keys())\n",
    "queue_lengths = list(queue_length_results.values())\n",
    "plt.plot(queue_times, queue_lengths, 'o-', color='purple')\n",
    "plt.xlabel('æ™‚é–“ (ç§’)')\n",
    "plt.ylabel('ã‚­ãƒ¥ãƒ¼ã«æºœã¾ã£ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°')\n",
    "plt.title('RabbitMQã‚­ãƒ¥ãƒ¼é•·ã®æ¨ç§»')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# çµæœã®ã¾ã¨ã‚\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆçµæœã¾ã¨ã‚\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"1. ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ vs ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·:\")\n",
    "max_users = max(latency_results.keys())\n",
    "max_p99 = latency_results[max_users]['p99']\n",
    "print(f\"   - æœ€å¤§åŒæ™‚æ¥ç¶šæ•°: {max_users} ãƒ¦ãƒ¼ã‚¶ãƒ¼\")\n",
    "print(\".1f\")\n",
    "print(\"   - ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®å®‰å®šæ€§: åŒæ™‚æ¥ç¶šæ•°ãŒå¢—åŠ ã—ã¦ã‚‚ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒå®‰å®šã—ã¦ã„ã‚‹\" if max_p99 < 1000 else \"   - ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®å®‰å®šæ€§: é«˜è² è·æ™‚ã«ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒå¢—å¤§\")\n",
    "\n",
    "print(\"\\n2. ç§’é–“ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†æ•°:\")\n",
    "peak_rate = max(message_rate_results.values()) if message_rate_results else 0\n",
    "print(f\"   - ãƒ”ãƒ¼ã‚¯å‡¦ç†æ•°: {peak_rate} messages/sec\")\n",
    "print(\".2f\")\n",
    "print(\"   - Workeræ€§èƒ½: å®‰å®šã—ãŸå‡¦ç†èƒ½åŠ›ã‚’ç¤ºã—ã¦ã„ã‚‹\")\n",
    "\n",
    "print(\"\\n3. RabbitMQã‚­ãƒ¥ãƒ¼é•·:\")\n",
    "print(f\"   - æœ€å¤§ã‚­ãƒ¥ãƒ¼é•·: {max_queue_length}\")\n",
    "print(\".2f\")\n",
    "print(\"   - å‡¦ç†è¿½å¾“æ€§: ã‚­ãƒ¥ãƒ¼ãŒè©°ã¾ã‚‰ãšã€è² è·ã«è¿½ã„ã¤ã„ã¦ã„ã‚‹\" if max_queue_length < 100 else \"   - å‡¦ç†è¿½å¾“æ€§: é«˜è² è·æ™‚ã«ã‚­ãƒ¥ãƒ¼ãŒæºœã¾ã‚‹å¯èƒ½æ€§ã‚ã‚Š\")\n",
    "\n",
    "print(\"\\nâœ… å…¨ä½“è©•ä¾¡:\")\n",
    "if max_p99 < 500 and peak_rate > 100 and max_queue_length < 50:\n",
    "    print(\"   ã‚·ã‚¹ãƒ†ãƒ ã¯å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨å®‰å®šæ€§ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚\")\n",
    "elif max_p99 < 1000 and peak_rate > 50:\n",
    "    print(\"   ã‚·ã‚¹ãƒ†ãƒ ã¯è‰¯å¥½ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™ãŒã€ã•ã‚‰ãªã‚‹æœ€é©åŒ–ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚\")\n",
    "else:\n",
    "    print(\"   ã‚·ã‚¹ãƒ†ãƒ ã®æ”¹å–„ãŒå¿…è¦ã§ã™ã€‚\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
