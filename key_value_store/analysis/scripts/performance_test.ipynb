{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d476bb7",
   "metadata": {},
   "source": [
    "# Key-Value Store Performance Testing\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯å„Key-Valueã‚¹ãƒˆã‚¢ã‚µãƒ¼ãƒ“ã‚¹ã®æ€§èƒ½ãƒ†ã‚¹ãƒˆã‚’è‡ªå‹•åŒ–ã—ã¾ã™ã€‚\n",
    "\n",
    "## å¯¾è±¡ã‚µãƒ¼ãƒ“ã‚¹\n",
    "1. **1-coordinator-ring**: ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ãƒªãƒ³ã‚°å®Ÿè£…\n",
    "2. **2-quorum-consistency**: ã‚¯ã‚©ãƒ¼ãƒ©ãƒ ä¸€è²«æ€§å®Ÿè£…\n",
    "3. **3-sharding-replica**: ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ»ãƒ¬ãƒ—ãƒªã‚«å®Ÿè£…\n",
    "4. **4-distributed-lock**: åˆ†æ•£ãƒ­ãƒƒã‚¯å®Ÿè£…\n",
    "5. **5-cache-aside**: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰å®Ÿè£…\n",
    "6. **6-bloom-sstable**: Bloomãƒ•ã‚£ãƒ«ã‚¿ã¨SSTableå®Ÿè£…\n",
    "7. **7-rate-limiting**: ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒ†ã‚£ãƒ³ã‚°å®Ÿè£…\n",
    "8. **8-line-streams**: Lineé¢¨ã‚¹ãƒˆãƒªãƒ¼ãƒ å®Ÿè£…\n",
    "9. **9-session-store**: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒˆã‚¢å®Ÿè£…\n",
    "10. **10-leaderboard**: ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰å®Ÿè£…\n",
    "\n",
    "## ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³\n",
    "- **è»½è² è·**: 10 clients, 1000 requests\n",
    "- **ä¸­è² è·**: 50 clients, 10000 requests  \n",
    "- **é«˜è² è·**: 100 clients, 50000 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7422c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸ\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import subprocess\n",
    "import requests\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import docker\n",
    "from contextlib import contextmanager\n",
    "import requests\n",
    "\n",
    "# ãƒ­ã‚°è¨­å®š\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ãƒ‘ã‚¹è¨­å®šï¼ˆavoid hard-coded user pathsï¼‰\n",
    "# Prefer Git repo root if available; fallback to searching upward from CWD.\n",
    "try:\n",
    "    repo_root = Path(\n",
    "        subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"], text=True).strip()\n",
    "    )\n",
    "except Exception:\n",
    "    repo_root = None\n",
    "\n",
    "base_dir = None\n",
    "if repo_root is not None and (repo_root / \"key_value_store\").exists():\n",
    "    base_dir = repo_root / \"key_value_store\"\n",
    "else:\n",
    "    for p in [Path.cwd(), *Path.cwd().parents]:\n",
    "        candidate = p / \"key_value_store\"\n",
    "        if candidate.exists():\n",
    "            base_dir = candidate\n",
    "            break\n",
    "\n",
    "if base_dir is None:\n",
    "    raise RuntimeError(\n",
    "        \"Could not locate 'key_value_store' directory. \"\n",
    "        \"Run this notebook from the repository root or ensure Git is available.\"\n",
    "    )\n",
    "\n",
    "BASE_DIR = base_dir\n",
    "DATA_DIR = BASE_DIR / \"analysis\" / \"data\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LOG_DIR = BASE_DIR / \"analysis\" / \"logs\"\n",
    "LOG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"âœ… å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4dd49d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVICES configured with 10 services\n"
     ]
    }
   ],
   "source": [
    "# --- SERVICES å®šç¾© ---\n",
    "SERVICES = {\n",
    "    \"1-coordinator-ring\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"write\": \"/write\",\n",
    "            \"read\": \"/read\"\n",
    "        },\n",
    "        \"test_data\": {\"key\": \"test_key\", \"value\": \"test_value\"}\n",
    "    },\n",
    "    \"2-quorum-consistency\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"write\": \"/write\",\n",
    "            \"read\": \"/read\"\n",
    "        },\n",
    "        \"test_data\": {\"key\": \"test_key\", \"value\": \"test_value\"}\n",
    "    },\n",
    "    \"3-sharding-replica\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"write\": \"/write\",\n",
    "            \"read\": \"/read\"\n",
    "        },\n",
    "        \"test_data\": {\"key\": \"test_key\", \"value\": \"test_value\"}\n",
    "    },\n",
    "    \"4-distributed-lock\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/stats\",\n",
    "            \"acquire\": \"/acquire\",\n",
    "            \"release\": \"/release\"\n",
    "        },\n",
    "        \"test_data\": {\"key\": \"test_resource\", \"owner\": \"test_client\"}\n",
    "    },\n",
    "    \"5-cache-aside\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"get\": \"/get\",\n",
    "            \"set\": \"/set\"\n",
    "        },\n",
    "        \"test_data\": {\"entity_type\": \"user\", \"entity_id\": \"1\", \"data\": {\"name\": \"test\"}}\n",
    "    },\n",
    "    \"6-bloom-sstable\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"write\": \"/write\",\n",
    "            \"read\": \"/read\"\n",
    "        },\n",
    "        \"test_data\": {\"key\": \"test_key\", \"value\": \"test_value\"}\n",
    "    },\n",
    "    \"7-rate-limiting\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"check\": \"/check_rate\"\n",
    "        },\n",
    "        \"test_data\": {\"user_id\": \"test_user\"}\n",
    "    },\n",
    "    \"8-line-streams\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"produce\": \"/produce\",\n",
    "            \"consume\": \"/consume\"\n",
    "        },\n",
    "        \"test_data\": {\"message\": \"test_message\", \"consumer\": \"test_consumer\"}\n",
    "    },\n",
    "    \"9-session-store\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"login\": \"/login\",\n",
    "            \"me\": \"/me\"\n",
    "        },\n",
    "        \"test_data\": {\"username\": \"test_user\"}\n",
    "    },\n",
    "    \"10-leaderboard\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"score\": \"/score\",\n",
    "            \"top\": \"/top/10\"\n",
    "        },\n",
    "        \"test_data\": {\"user_id\": \"test_user\", \"score\": 100}\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"SERVICES configured with\", len(SERVICES), \"services\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23be3da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATTERNS = {\n",
    "    \"light\": {\n",
    "        \"description\": \"è»½è² è·\",\n",
    "        \"clients\": 10,\n",
    "        \"requests\": 1000,\n",
    "        \"timeout\": 30,\n",
    "        \"ramp_up\": 5\n",
    "    },\n",
    "    \"medium\": {\n",
    "        \"description\": \"ä¸­è² è·\",\n",
    "        \"clients\": 50,\n",
    "        \"requests\": 10000,\n",
    "        \"timeout\": 60,\n",
    "        \"ramp_up\": 10\n",
    "    },\n",
    "    \"heavy\": {\n",
    "        \"description\": \"é«˜è² è·\",\n",
    "        \"clients\": 100,\n",
    "        \"requests\": 50000,\n",
    "        \"timeout\": 120,\n",
    "        \"ramp_up\": 20\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73efcc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DockerManager:\n",
    "    \"\"\"Dockerã‚³ãƒ³ãƒ†ãƒŠã®ç®¡ç†ã‚¯ãƒ©ã‚¹\"\"\"\n",
    "\n",
    "    def __init__(self, service_name):\n",
    "        self.service_name = service_name\n",
    "        self.service_dir = BASE_DIR / service_name\n",
    "        self.client = docker.from_env()\n",
    "\n",
    "    def start_service(self):\n",
    "        \"\"\"ã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•\"\"\"\n",
    "        try:\n",
    "            cmd = [\"docker\", \"compose\", \"up\", \"-d\", \"--build\"]\n",
    "            result = subprocess.run(\n",
    "                cmd, cwd=self.service_dir,\n",
    "                capture_output=True, text=True, timeout=300\n",
    "            )\n",
    "            time.sleep(30)\n",
    "            if result.returncode != 0:\n",
    "                logger.error(f\"âŒ {self.service_name} èµ·å‹•å¤±æ•—: {result.stderr}\")\n",
    "                self.save_container_logs()\n",
    "                return False\n",
    "            return True\n",
    "        except subprocess.TimeoutExpired:\n",
    "            logger.error(f\"âŒ {self.service_name} èµ·å‹•ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ\")\n",
    "            self.save_container_logs()\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ {self.service_name} èµ·å‹•ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            self.save_container_logs()\n",
    "            return False\n",
    "\n",
    "    def stop_service(self):\n",
    "        \"\"\"ã‚µãƒ¼ãƒ“ã‚¹ã‚’åœæ­¢\"\"\"\n",
    "        try:\n",
    "            cmd = [\"docker\", \"compose\", \"down\", \"-v\"]\n",
    "            result = subprocess.run(\n",
    "                cmd, cwd=self.service_dir,\n",
    "                capture_output=True, text=True, timeout=60\n",
    "            )\n",
    "            if result.returncode != 0:\n",
    "                logger.warning(f\"âš ï¸ {self.service_name} åœæ­¢æ™‚ã«è­¦å‘Š: {result.stderr}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ {self.service_name} åœæ­¢ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "\n",
    "    def health_check(self, max_retries=60):\n",
    "        \"\"\"ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯\"\"\"\n",
    "        service_config = SERVICES[self.service_name]\n",
    "        health_url = f\"http://localhost:{service_config['port']}{service_config['endpoints']['health']}\"\n",
    "\n",
    "        if self.service_name in ['5-cache-aside', '3-sharding-replica']:\n",
    "            max_retries = 90  # DBä¾å­˜ã‚µãƒ¼ãƒ“ã‚¹ã¯é•·ã‚ã«å¾…æ©Ÿ\n",
    "\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = requests.get(health_url, timeout=5)\n",
    "                if response.status_code == 200:\n",
    "                    return True\n",
    "            except requests.exceptions.RequestException:\n",
    "                pass\n",
    "            time.sleep(2)\n",
    "\n",
    "        logger.error(f\"âŒ {self.service_name} ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¤±æ•— ({max_retries}å›è©¦è¡Œ)\")\n",
    "        self.save_container_logs()\n",
    "        return False\n",
    "\n",
    "    def save_container_logs(self):\n",
    "        \"\"\"ã‚³ãƒ³ãƒ†ãƒŠã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜\"\"\"\n",
    "        try:\n",
    "            containers = self._find_containers()\n",
    "            for container in containers:\n",
    "                logs = container.logs(tail=200).decode(\"utf-8\", errors=\"ignore\")\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                log_file = LOG_DIR / f\"{self.service_name}_{container.name}_{timestamp}.log\"\n",
    "                with open(log_file, \"w\") as f:\n",
    "                    f.write(logs)\n",
    "                logger.error(f\"ğŸ“„ {self.service_name} ({container.name}) ã®ãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {log_file}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"âš ï¸ {self.service_name} ãƒ­ã‚°ä¿å­˜å¤±æ•—: {str(e)}\")\n",
    "\n",
    "    def _find_containers(self):\n",
    "        \"\"\"ã‚³ãƒ³ãƒ†ãƒŠã‚’è¤‡æ•°ã®æ–¹æ³•ã§æ¤œç´¢ï¼ˆå …ç‰¢åŒ–ï¼‰\"\"\"\n",
    "        containers = []\n",
    "\n",
    "        # æ–¹æ³•1: å…ƒã®å®Ÿè£…ï¼ˆãƒã‚¤ãƒ•ãƒ³å‰Šé™¤ï¼‰\n",
    "        try:\n",
    "            project_name = self.service_name.replace('-', '')\n",
    "            containers = self.client.containers.list(\n",
    "                filters={\"label\": f\"com.docker.compose.project={project_name}\"}\n",
    "            )\n",
    "            if containers:\n",
    "                logger.debug(f\"Found {len(containers)} containers using project name: {project_name}\")\n",
    "                return containers\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Method 1 failed: {e}\")\n",
    "\n",
    "        # æ–¹æ³•2: ãƒã‚¤ãƒ•ãƒ³ãã®ã¾ã¾\n",
    "        try:\n",
    "            containers = self.client.containers.list(\n",
    "                filters={\"label\": f\"com.docker.compose.project={self.service_name}\"}\n",
    "            )\n",
    "            if containers:\n",
    "                logger.debug(f\"Found {len(containers)} containers using project name: {self.service_name}\")\n",
    "                return containers\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Method 2 failed: {e}\")\n",
    "\n",
    "        # æ–¹æ³•3: ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ç½®æ›\n",
    "        try:\n",
    "            project_name = self.service_name.replace('-', '_')\n",
    "            containers = self.client.containers.list(\n",
    "                filters={\"label\": f\"com.docker.compose.project={project_name}\"}\n",
    "            )\n",
    "            if containers:\n",
    "                logger.debug(f\"Found {len(containers)} containers using project name: {project_name}\")\n",
    "                return containers\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Method 3 failed: {e}\")\n",
    "\n",
    "        # æ–¹æ³•4: åå‰ãƒ™ãƒ¼ã‚¹ãƒãƒƒãƒãƒ³ã‚°ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\n",
    "        try:\n",
    "            all_containers = self.client.containers.list()\n",
    "            containers = [c for c in all_containers if self.service_name in c.name or\n",
    "                         self.service_name.replace('-', '') in c.name]\n",
    "            if containers:\n",
    "                logger.debug(f\"Found {len(containers)} containers using name matching\")\n",
    "                return containers\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Method 4 failed: {e}\")\n",
    "\n",
    "        logger.warning(f\"âš ï¸ {self.service_name} ã®ã‚³ãƒ³ãƒ†ãƒŠãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "        return []\n",
    "\n",
    "    def get_container_stats(self):\n",
    "        \"\"\"ã‚³ãƒ³ãƒ†ãƒŠã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ï¼ˆæ”¹è‰¯ç‰ˆï¼‰\"\"\"\n",
    "        try:\n",
    "            containers = self._find_containers()\n",
    "            if not containers:\n",
    "                logger.warning(f\"âš ï¸ {self.service_name} ã®çµ±è¨ˆæƒ…å ±å–å¾—: ã‚³ãƒ³ãƒ†ãƒŠãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "                return {}\n",
    "\n",
    "            stats = {}\n",
    "            for container in containers:\n",
    "                try:\n",
    "                    container_stats = container.stats(stream=False)\n",
    "                    stats[container.name] = {\n",
    "                        \"cpu_percent\": self._calculate_cpu_percent(container_stats),\n",
    "                        \"memory_usage\": container_stats.get(\"memory_stats\", {}).get(\"usage\", 0),\n",
    "                        \"memory_limit\": container_stats.get(\"memory_stats\", {}).get(\"limit\", 0)\n",
    "                    }\n",
    "                    logger.debug(f\"Stats collected for {container.name}: CPU={stats[container.name]['cpu_percent']:.2f}%, Memory={stats[container.name]['memory_usage']}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"âš ï¸ ã‚³ãƒ³ãƒ†ãƒŠ {container.name} ã®çµ±è¨ˆå–å¾—å¤±æ•—: {e}\")\n",
    "\n",
    "            logger.info(f\"âœ… {self.service_name} ã®çµ±è¨ˆæƒ…å ±ã‚’ {len(stats)} ã‚³ãƒ³ãƒ†ãƒŠã‹ã‚‰å–å¾—ã—ã¾ã—ãŸ\")\n",
    "            return stats\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"âš ï¸ {self.service_name} çµ±è¨ˆæƒ…å ±å–å¾—å¤±æ•—: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def _calculate_cpu_percent(self, stats):\n",
    "        \"\"\"CPUä½¿ç”¨ç‡ã‚’è¨ˆç®—\"\"\"\n",
    "        try:\n",
    "            cpu_stats = stats.get(\"cpu_stats\", {})\n",
    "            precpu_stats = stats.get(\"precpu_stats\", {})\n",
    "\n",
    "            cpu_delta = (\n",
    "                cpu_stats.get(\"cpu_usage\", {}).get(\"total_usage\", 0)\n",
    "                - precpu_stats.get(\"cpu_usage\", {}).get(\"total_usage\", 0)\n",
    "            )\n",
    "            system_delta = (\n",
    "                cpu_stats.get(\"system_cpu_usage\", 0)\n",
    "                - precpu_stats.get(\"system_cpu_usage\", 0)\n",
    "            )\n",
    "\n",
    "            percpu_usage = cpu_stats.get(\"cpu_usage\", {}).get(\"percpu_usage\", [])\n",
    "            num_cpus = len(percpu_usage) if percpu_usage else 1\n",
    "\n",
    "            if system_delta > 0 and cpu_delta >= 0:\n",
    "                return (cpu_delta / system_delta) * num_cpus * 100.0\n",
    "        except (KeyError, ZeroDivisionError, TypeError) as e:\n",
    "            logger.debug(f\"CPUè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "            pass\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897224a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ€§èƒ½ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ï¼ˆé€æ¬¡å‡¦ç†ç‰ˆï¼‰ãŒå®šç¾©ã•ã‚Œã¾ã—ãŸ\n"
     ]
    }
   ],
   "source": [
    "class PerformanceTester:\n",
    "    \"\"\"æ€§èƒ½ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¯ãƒ©ã‚¹\"\"\"\n",
    "\n",
    "    def __init__(self, service_name):\n",
    "        self.service_name = service_name\n",
    "        self.service_config = SERVICES[service_name]\n",
    "        self.base_url = f\"http://localhost:{self.service_config['port']}\"\n",
    "        self.results = []\n",
    "        self.session = requests.Session()  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ç”¨\n",
    "\n",
    "    def run_single_request(self, endpoint, method=\"GET\", data=None, session=None):\n",
    "        \"\"\"å˜ä¸€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å®Ÿè¡Œã¨æ¸¬å®š\"\"\"\n",
    "        use_session = session if session else (\n",
    "            self.session if self.service_name == '9-session-store' else None\n",
    "        )\n",
    "\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            if method == \"POST\":\n",
    "                response = (use_session or requests).post(url, json=data, timeout=10)\n",
    "            else:\n",
    "                response = (use_session or requests).get(url, params=data, timeout=10)\n",
    "\n",
    "            response_time = (time.time() - start_time) * 1000  # ãƒŸãƒªç§’\n",
    "\n",
    "            result = {\n",
    "                \"response_time\": response_time,\n",
    "                \"status_code\": response.status_code,\n",
    "                \"success\": 200 <= response.status_code < 300,\n",
    "                \"error\": None\n",
    "            }\n",
    "\n",
    "            # 9-session-store ã®å ´åˆã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ä¿æŒ\n",
    "            if (self.service_name == '9-session-store' and\n",
    "                endpoint == '/login' and\n",
    "                response.status_code == 200 and\n",
    "                use_session is not None):\n",
    "                try:\n",
    "                    response_data = response.json()\n",
    "                    if 'session_id' in response_data:\n",
    "                        use_session.cookies.set('session_id', response_data['session_id'])\n",
    "                except Exception:\n",
    "                    pass  # JSON ãƒ‘ãƒ¼ã‚¹å¤±æ•—ã¯ç„¡è¦–\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"response_time\": (time.time() - start_time) * 1000,\n",
    "                \"status_code\": 0,\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "    def run_load_test(self, pattern_name, docker_manager):\n",
    "        \"\"\"è² è·ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œï¼ˆé€æ¬¡å‡¦ç†ç‰ˆï¼‰\"\"\"\n",
    "        pattern = TEST_PATTERNS[pattern_name]\n",
    "        clients = pattern[\"clients\"]\n",
    "        total_requests = pattern[\"requests\"]\n",
    "        requests_per_client = total_requests // clients\n",
    "\n",
    "        print(f\"ğŸ§ª {self.service_name} - {pattern['description']} é–‹å§‹\")\n",
    "        print(f\"   ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ•°: {clients}, ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {total_requests}\")\n",
    "\n",
    "        # ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæ±ºå®š\n",
    "        test_endpoint, test_method, test_data = self._get_test_endpoint()\n",
    "\n",
    "        # 9-session-store ã®å ´åˆã¯äº‹å‰ãƒ­ã‚°ã‚¤ãƒ³\n",
    "        if self.service_name == '9-session-store':\n",
    "            login_result = self.run_single_request('/login', 'POST', {'username': 'test_user'})\n",
    "            if not login_result['success']:\n",
    "                raise RuntimeError(f\"Login failed for {self.service_name}\")\n",
    "\n",
    "        initial_stats = docker_manager.get_container_stats()\n",
    "        start_time = time.time()\n",
    "\n",
    "        all_results = []\n",
    "        for client_id in range(clients):\n",
    "            client_results = self._client_worker(\n",
    "                client_id, requests_per_client, test_endpoint, test_method, test_data\n",
    "            )\n",
    "            all_results.extend(client_results)\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "        final_stats = docker_manager.get_container_stats()\n",
    "\n",
    "        analysis = self._analyze_results(all_results, duration, initial_stats, final_stats)\n",
    "        analysis.update({\n",
    "            \"service_name\": self.service_name,\n",
    "            \"pattern_name\": pattern_name,\n",
    "            \"pattern_description\": pattern[\"description\"],\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"clients\": clients,\n",
    "            \"total_requests\": len(all_results),\n",
    "            \"duration\": duration\n",
    "        })\n",
    "\n",
    "        print(f\"âœ… {self.service_name} - {pattern['description']} å®Œäº†\")\n",
    "        print(f\"   å®Ÿè¡Œæ™‚é–“: {duration:.2f}ç§’, QPS: {analysis['qps']:.2f}\")\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    def _get_test_endpoint(self):\n",
    "        \"\"\"ã‚µãƒ¼ãƒ“ã‚¹ã”ã¨ã®ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æ±ºå®š\"\"\"\n",
    "        endpoints = self.service_config[\"endpoints\"]\n",
    "        test_data = self.service_config[\"test_data\"]\n",
    "\n",
    "        if self.service_name == '9-session-store':\n",
    "            return endpoints[\"me\"], \"GET\", None\n",
    "        elif self.service_name == '5-cache-aside':\n",
    "            entity_type = test_data['entity_type']\n",
    "            entity_id = test_data['entity_id']\n",
    "            return f\"/set/{entity_type}/{entity_id}\", \"POST\", test_data['data']\n",
    "        elif \"write\" in endpoints:\n",
    "            return endpoints[\"write\"], \"POST\", test_data\n",
    "        elif \"put\" in endpoints:\n",
    "            return endpoints[\"put\"], \"POST\", test_data\n",
    "        elif \"publish\" in endpoints:\n",
    "            return endpoints[\"publish\"], \"POST\", test_data\n",
    "        elif \"produce\" in endpoints:\n",
    "            return endpoints[\"produce\"], \"POST\", test_data\n",
    "        elif \"acquire\" in endpoints:\n",
    "            return endpoints[\"acquire\"], \"POST\", test_data\n",
    "        elif \"score\" in endpoints:\n",
    "            return endpoints[\"score\"], \"POST\", test_data\n",
    "        else:\n",
    "            return endpoints[\"health\"], \"GET\", None\n",
    "\n",
    "    def _client_worker(self, client_id, requests_count, endpoint, method, data):\n",
    "        \"\"\"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã”ã¨ã®é€æ¬¡ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†\"\"\"\n",
    "        results = []\n",
    "\n",
    "        # 9-session-store ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã”ã¨ã«ãƒ­ã‚°ã‚¤ãƒ³\n",
    "        if self.service_name == '9-session-store':\n",
    "            client_session = requests.Session()\n",
    "            login_data = {'username': f'test_user_{client_id}'}\n",
    "            login_result = self.run_single_request('/login', 'POST', login_data, client_session)\n",
    "            if not login_result['success']:\n",
    "                return []\n",
    "        else:\n",
    "            client_session = None\n",
    "\n",
    "        for i in range(requests_count):\n",
    "            test_data = self._prepare_dynamic_data(data, client_id, i)\n",
    "            current_endpoint = endpoint\n",
    "\n",
    "            # 5-cache-aside ã¯ entity_id ã‚’å‹•çš„å¤‰æ›´\n",
    "            if self.service_name == '5-cache-aside':\n",
    "                etype = self.service_config['test_data']['entity_type']\n",
    "                eid = f\"{self.service_config['test_data']['entity_id']}_{client_id}_{i}\"\n",
    "                current_endpoint = f\"/set/{etype}/{eid}\"\n",
    "\n",
    "            result = self.run_single_request(current_endpoint, method, test_data, client_session)\n",
    "            result.update({\"client_id\": client_id, \"request_id\": i})\n",
    "            results.append(result)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _prepare_dynamic_data(self, data, client_id, i):\n",
    "        \"\"\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å‹•çš„ã«ç”Ÿæˆ\"\"\"\n",
    "        if not data:\n",
    "            return None\n",
    "\n",
    "        test_data = data.copy()\n",
    "        if \"key\" in test_data:\n",
    "            test_data[\"key\"] = f\"{test_data['key']}_{client_id}_{i}\"\n",
    "        if \"resource\" in test_data:\n",
    "            test_data[\"resource\"] = f\"{test_data['resource']}_{client_id}_{i}\"\n",
    "        if \"client_id\" in test_data:\n",
    "            test_data[\"client_id\"] = f\"{test_data['client_id']}_{client_id}\"\n",
    "        if \"user_id\" in test_data:\n",
    "            test_data[\"user_id\"] = f\"{test_data['user_id']}_{client_id}_{i}\"\n",
    "        if \"score\" in test_data:\n",
    "            test_data[\"score\"] = test_data[\"score\"] + i\n",
    "        return test_data\n",
    "\n",
    "    def _analyze_results(self, results, duration, initial_stats, final_stats):\n",
    "        \"\"\"çµæœåˆ†æ\"\"\"\n",
    "        successful = [r for r in results if r[\"success\"]]\n",
    "        times = [r[\"response_time\"] for r in successful]\n",
    "\n",
    "        if not times:\n",
    "            return {\n",
    "                \"total_requests\": len(results),\n",
    "                \"successful_requests\": 0,\n",
    "                \"error_rate\": 100.0,\n",
    "                \"qps\": 0.0,\n",
    "                \"avg_response_time\": 0.0,\n",
    "                \"median_response_time\": 0.0,\n",
    "                \"p95_response_time\": 0.0,\n",
    "                \"p99_response_time\": 0.0,\n",
    "                \"min_response_time\": 0.0,\n",
    "                \"max_response_time\": 0.0\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            \"total_requests\": len(results),\n",
    "            \"successful_requests\": len(successful),\n",
    "            \"error_rate\": ((len(results) - len(successful)) / len(results)) * 100,\n",
    "            \"qps\": len(successful) / duration,\n",
    "            \"avg_response_time\": statistics.mean(times),\n",
    "            \"median_response_time\": statistics.median(times),\n",
    "            \"p95_response_time\": np.percentile(times, 95),\n",
    "            \"p99_response_time\": np.percentile(times, 99),\n",
    "            \"min_response_time\": min(times),\n",
    "            \"max_response_time\": max(times),\n",
    "            \"initial_stats\": initial_stats,\n",
    "            \"final_stats\": final_stats\n",
    "        }\n",
    "\n",
    "print(\"âœ… æ€§èƒ½ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ï¼ˆé€æ¬¡å‡¦ç†ç‰ˆï¼‰ãŒå®šç¾©ã•ã‚Œã¾ã—ãŸ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e787ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ã‚µãƒ¼ãƒ“ã‚¹ç®¡ç†ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒå®šç¾©ã•ã‚Œã¾ã—ãŸ\n"
     ]
    }
   ],
   "source": [
    "@contextmanager\n",
    "def service_context(service_name):\n",
    "    \"\"\"ã‚µãƒ¼ãƒ“ã‚¹ã®èµ·å‹•ã¨åœæ­¢ã‚’ç®¡ç†ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£\"\"\"\n",
    "    logger.info(f\"ğŸ”„ {service_name} ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’é–‹å§‹...\")\n",
    "    docker_manager = DockerManager(service_name)\n",
    "    time.sleep(30)  # å°‘ã—å¾…ã£ã¦ã‹ã‚‰æ“ä½œé–‹å§‹\n",
    "\n",
    "    # æ—¢å­˜ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "    docker_manager.stop_service()\n",
    "\n",
    "    if not docker_manager.start_service():\n",
    "        raise RuntimeError(f\"{service_name} ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\")\n",
    "\n",
    "    if not docker_manager.health_check():\n",
    "        docker_manager.stop_service()\n",
    "        raise RuntimeError(f\"{service_name} ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\")\n",
    "\n",
    "    logger.info(f\"âœ… {service_name} ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")\n",
    "\n",
    "    try:\n",
    "        yield docker_manager\n",
    "    finally:\n",
    "        logger.info(f\"ğŸ§¹ {service_name} ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹...\")\n",
    "        docker_manager.stop_service()\n",
    "        logger.info(f\"âœ… {service_name} ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")\n",
    "    time.sleep(30)  # æ¬¡ã®ã‚µãƒ¼ãƒ“ã‚¹ã®ãŸã‚ã«å°‘ã—å¾…æ©Ÿ\n",
    "\n",
    "print(\"âœ… ã‚µãƒ¼ãƒ“ã‚¹ç®¡ç†ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒå®šç¾©ã•ã‚Œã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d1034b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–¢æ•°ãŒå®šç¾©ã•ã‚Œã¾ã—ãŸ\n"
     ]
    }
   ],
   "source": [
    "def run_comprehensive_test(selected_services=None, selected_patterns=None):\n",
    "    \"\"\"åŒ…æ‹¬çš„ãªæ€§èƒ½ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ\"\"\"\n",
    "    if selected_services is None:\n",
    "        selected_services = list(SERVICES.keys())\n",
    "    if selected_patterns is None:\n",
    "        selected_patterns = list(TEST_PATTERNS.keys())\n",
    "\n",
    "    all_results = []\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    logger.info(f\"ğŸš€ åŒ…æ‹¬çš„æ€§èƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹ - {timestamp}\")\n",
    "    logger.info(f\"å¯¾è±¡ã‚µãƒ¼ãƒ“ã‚¹: {selected_services}\")\n",
    "    logger.info(f\"ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³: {selected_patterns}\")\n",
    "\n",
    "    total_tests = len(selected_services) * len(selected_patterns)\n",
    "    current_test = 0\n",
    "\n",
    "    for service_name in selected_services:\n",
    "        logger.info(f\"\\nğŸ“Š {service_name} ã®ãƒ†ã‚¹ãƒˆé–‹å§‹\")\n",
    "\n",
    "        try:\n",
    "            with service_context(service_name) as docker_manager:\n",
    "                tester = PerformanceTester(service_name)\n",
    "\n",
    "                for pattern_name in selected_patterns:\n",
    "                    current_test += 1\n",
    "                    logger.info(f\"\\né€²è¡ŒçŠ¶æ³: {current_test}/{total_tests}\")\n",
    "\n",
    "                    try:\n",
    "                        result = tester.run_load_test(pattern_name, docker_manager)\n",
    "                        all_results.append(result)\n",
    "\n",
    "                        # ä¸­é–“çµæœä¿å­˜\n",
    "                        save_results([result], f\"intermediate_{service_name}_{pattern_name}_{timestamp}\")\n",
    "\n",
    "                        # ãƒ†ã‚¹ãƒˆé–“ã®ä¼‘æ†©\n",
    "                        if current_test < total_tests:\n",
    "                            logger.info(\"â¸ï¸ 5ç§’é–“ã®ä¼‘æ†©...\")\n",
    "                            time.sleep(5)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"âŒ {service_name} - {pattern_name} ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}\")\n",
    "                        # ã‚¨ãƒ©ãƒ¼çµæœã‚‚è¨˜éŒ²\n",
    "                        error_result = {\n",
    "                            \"service_name\": service_name,\n",
    "                            \"pattern_name\": pattern_name,\n",
    "                            \"error\": str(e),\n",
    "                            \"timestamp\": datetime.now().isoformat()\n",
    "                        }\n",
    "                        all_results.append(error_result)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ {service_name} ã‚µãƒ¼ãƒ“ã‚¹å…¨ä½“ã®ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # æœ€çµ‚çµæœä¿å­˜\n",
    "    save_results(all_results, f\"comprehensive_test_{timestamp}\")\n",
    "\n",
    "    logger.info(f\"\\nğŸ‰ å…¨ãƒ†ã‚¹ãƒˆå®Œäº†! çµæœã¯ {DATA_DIR} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ\")\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def save_results(results, filename_prefix):\n",
    "    \"\"\"çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\n",
    "\n",
    "    - JSONã¯å…ƒã®ã¾ã¾ä¿å­˜\n",
    "    - CSVã«ã¯ initial_stats / final_stats ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–ã—ãŸæ•°å€¤åˆ—ã‚’è¿½åŠ ã—ã¦å‡ºåŠ›\n",
    "    \"\"\"\n",
    "    # JSONå½¢å¼ã§ä¿å­˜ï¼ˆå¸¸ã«ä¿å­˜ï¼‰\n",
    "    json_file = DATA_DIR / f\"{filename_prefix}.json\"\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # CSVå½¢å¼ã§ä¿å­˜ï¼ˆæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰\n",
    "    csv_file = DATA_DIR / f\"{filename_prefix}.csv\"\n",
    "\n",
    "    # ãƒ˜ãƒ«ãƒ‘ãƒ¼: ã‚³ãƒ³ãƒ†ãƒŠå˜ä½ã® stats ã‚’é›†ç´„ã—ã¦æ•°å€¤åˆ—ã‚’ä½œã‚‹\n",
    "    def _flatten_stats(stats):\n",
    "        # stats: {container_name: {\"cpu_percent\": .., \"memory_usage\": .., \"memory_limit\": ..}, ...}\n",
    "        if not stats or not isinstance(stats, dict):\n",
    "            return {}\n",
    "\n",
    "        cpu_vals = []\n",
    "        mem_vals = []\n",
    "        mem_limits = []\n",
    "        for _, s in stats.items():\n",
    "            try:\n",
    "                cpu_vals.append(float(s.get('cpu_percent', 0.0)))\n",
    "            except Exception:\n",
    "                pass\n",
    "            try:\n",
    "                mem_vals.append(float(s.get('memory_usage', 0.0)))\n",
    "            except Exception:\n",
    "                pass\n",
    "            try:\n",
    "                mem_limits.append(float(s.get('memory_limit', 0.0)))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        out = {}\n",
    "        out['cpu_avg'] = statistics.mean(cpu_vals) if cpu_vals else 0.0\n",
    "        out['cpu_max'] = max(cpu_vals) if cpu_vals else 0.0\n",
    "        out['mem_usage_avg'] = statistics.mean(mem_vals) if mem_vals else 0.0\n",
    "        out['mem_usage_max'] = max(mem_vals) if mem_vals else 0.0\n",
    "        out['mem_limit_total'] = sum(mem_limits) if mem_limits else 0.0\n",
    "        return out\n",
    "\n",
    "    # CSV å‡ºåŠ›ç”¨ã«çµæœã‚’è¤‡è£½ã—ã¦ãƒ•ãƒ©ãƒƒãƒˆãªæ•°å€¤åˆ—ã‚’è¿½åŠ \n",
    "    try:\n",
    "        flattened_results = []\n",
    "        for r in results:\n",
    "            rr = dict(r)  # shallow copy\n",
    "\n",
    "            if 'initial_stats' in r and isinstance(r['initial_stats'], dict):\n",
    "                flat_init = _flatten_stats(r['initial_stats'])\n",
    "                for k, v in flat_init.items():\n",
    "                    rr[f'initial_{k}'] = v\n",
    "\n",
    "            if 'final_stats' in r and isinstance(r['final_stats'], dict):\n",
    "                flat_final = _flatten_stats(r['final_stats'])\n",
    "                for k, v in flat_final.items():\n",
    "                    rr[f'final_{k}'] = v\n",
    "\n",
    "            flattened_results.append(rr)\n",
    "\n",
    "        # ã‚¨ãƒ©ãƒ¼ãŒãªã„å ´åˆã€æ•°å€¤åˆ—ã‚’å«ã‚ã¦CSVå‡ºåŠ›\n",
    "        if flattened_results and not any('error' in r for r in flattened_results):\n",
    "            df = pd.DataFrame(flattened_results)\n",
    "            # åˆæœŸã®è¤‡é›‘ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåˆ—ã¯ CSV ã«å«ã‚ãªã„\n",
    "            drop_cols = [c for c in ['initial_stats', 'final_stats'] if c in df.columns]\n",
    "            if drop_cols:\n",
    "                df = df.drop(columns=drop_cols)\n",
    "\n",
    "            # æ•°å€¤ã¾ãŸã¯å˜ç´”ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåˆ—ã«çµã‚‹ï¼ˆæ–‡å­—åˆ—ãªã©ã‚‚å«ã‚ã¦è§£æã—ã‚„ã™ã„å½¢ã§å‡ºåŠ›ï¼‰\n",
    "            numeric_columns = df.select_dtypes(include=[np.number, 'object']).columns\n",
    "            simple_columns = [col for col in numeric_columns]\n",
    "            df[simple_columns].to_csv(csv_file, index=False)\n",
    "\n",
    "        logger.info(f\"ğŸ’¾ çµæœä¿å­˜å®Œäº†: {json_file}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"âš ï¸ çµæœä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "\n",
    "print(\"âœ… ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–¢æ•°ãŒå®šç¾©ã•ã‚Œã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24613c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹é–¢æ•°ãŒå®šç¾©ã•ã‚Œã¾ã—ãŸ\n",
      "\n",
      "ğŸ¯ ä½¿ç”¨æ–¹æ³•:\n",
      "  - show_services(): ã‚µãƒ¼ãƒ“ã‚¹ä¸€è¦§è¡¨ç¤º\n",
      "  - show_patterns(): ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§è¡¨ç¤º\n",
      "  - quick_test('service_name', 'pattern_name'): å˜ä¸€ã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ\n",
      "  - test_all_services('pattern_name'): å…¨ã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ\n",
      "  - test_service_all_patterns('service_name'): æŒ‡å®šã‚µãƒ¼ãƒ“ã‚¹å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ\n",
      "  - run_comprehensive_test(): å®Œå…¨ãªã‚«ã‚¹ã‚¿ãƒ ãƒ†ã‚¹ãƒˆ\n"
     ]
    }
   ],
   "source": [
    "# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç”¨é–¢æ•°\n",
    "\n",
    "def show_services():\n",
    "    \"\"\"åˆ©ç”¨å¯èƒ½ãªã‚µãƒ¼ãƒ“ã‚¹ä¸€è¦§ã‚’è¡¨ç¤º\"\"\"\n",
    "    print(\"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªã‚µãƒ¼ãƒ“ã‚¹:\")\n",
    "    for i, (name, config) in enumerate(SERVICES.items(), 1):\n",
    "        print(f\"  {i}. {name} (ãƒãƒ¼ãƒˆ: {config['port']})\")\n",
    "\n",
    "def show_patterns():\n",
    "    \"\"\"åˆ©ç”¨å¯èƒ½ãªãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§ã‚’è¡¨ç¤º\"\"\"\n",
    "    print(\"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³:\")\n",
    "    for i, (name, pattern) in enumerate(TEST_PATTERNS.items(), 1):\n",
    "        print(f\"  {i}. {name}: {pattern['description']} ({pattern['clients']} clients, {pattern['requests']} requests)\")\n",
    "\n",
    "def quick_test(service_name, pattern_name=\"light\"):\n",
    "    \"\"\"å˜ä¸€ã‚µãƒ¼ãƒ“ã‚¹ã®ç°¡æ˜“ãƒ†ã‚¹ãƒˆ\"\"\"\n",
    "    if service_name not in SERVICES:\n",
    "        print(f\"âŒ ã‚µãƒ¼ãƒ“ã‚¹ '{service_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        show_services()\n",
    "        return None\n",
    "\n",
    "    if pattern_name not in TEST_PATTERNS:\n",
    "        print(f\"âŒ ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        show_patterns()\n",
    "        return None\n",
    "\n",
    "    return run_comprehensive_test([service_name], [pattern_name])\n",
    "\n",
    "def test_all_services(pattern_name=\"light\"):\n",
    "    \"\"\"å…¨ã‚µãƒ¼ãƒ“ã‚¹ã®æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã®ãƒ†ã‚¹ãƒˆ\"\"\"\n",
    "    if pattern_name not in TEST_PATTERNS:\n",
    "        print(f\"âŒ ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        show_patterns()\n",
    "        return None\n",
    "\n",
    "    return run_comprehensive_test(None, [pattern_name])\n",
    "\n",
    "def test_service_all_patterns(service_name):\n",
    "    \"\"\"æŒ‡å®šã‚µãƒ¼ãƒ“ã‚¹ã®å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã®ãƒ†ã‚¹ãƒˆ\"\"\"\n",
    "    if service_name not in SERVICES:\n",
    "        print(f\"âŒ ã‚µãƒ¼ãƒ“ã‚¹ '{service_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        show_services()\n",
    "        return None\n",
    "\n",
    "    return run_comprehensive_test([service_name], None)\n",
    "\n",
    "print(\"âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹é–¢æ•°ãŒå®šç¾©ã•ã‚Œã¾ã—ãŸ\")\n",
    "print(\"\\nğŸ¯ ä½¿ç”¨æ–¹æ³•:\")\n",
    "print(\"  - show_services(): ã‚µãƒ¼ãƒ“ã‚¹ä¸€è¦§è¡¨ç¤º\")\n",
    "print(\"  - show_patterns(): ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§è¡¨ç¤º\")\n",
    "print(\"  - quick_test('service_name', 'pattern_name'): å˜ä¸€ã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ\")\n",
    "print(\"  - test_all_services('pattern_name'): å…¨ã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ\")\n",
    "print(\"  - test_service_all_patterns('service_name'): æŒ‡å®šã‚µãƒ¼ãƒ“ã‚¹å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ\")\n",
    "print(\"  - run_comprehensive_test(): å®Œå…¨ãªã‚«ã‚¹ã‚¿ãƒ ãƒ†ã‚¹ãƒˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fa8002",
   "metadata": {},
   "source": [
    "## ğŸš€ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¾‹\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚ãƒ†ã‚¹ãƒˆå‰ã«å¿…è¦ã«å¿œã˜ã¦è¨­å®šã‚’ç¢ºèªãƒ»å¤‰æ›´ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee4724dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªã‚µãƒ¼ãƒ“ã‚¹:\n",
      "  1. 1-coordinator-ring (ãƒãƒ¼ãƒˆ: 8000)\n",
      "  2. 2-quorum-consistency (ãƒãƒ¼ãƒˆ: 8000)\n",
      "  3. 3-sharding-replica (ãƒãƒ¼ãƒˆ: 8000)\n",
      "  4. 4-distributed-lock (ãƒãƒ¼ãƒˆ: 8000)\n",
      "  5. 5-cache-aside (ãƒãƒ¼ãƒˆ: 8000)\n",
      "  6. 6-bloom-sstable (ãƒãƒ¼ãƒˆ: 8000)\n",
      "  7. 7-rate-limiting (ãƒãƒ¼ãƒˆ: 8000)\n",
      "  8. 8-line-streams (ãƒãƒ¼ãƒˆ: 8000)\n",
      "  9. 9-session-store (ãƒãƒ¼ãƒˆ: 8000)\n",
      "  10. 10-leaderboard (ãƒãƒ¼ãƒˆ: 8000)\n",
      "\n",
      "ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³:\n",
      "  1. light: è»½è² è· (10 clients, 1000 requests)\n",
      "  2. medium: ä¸­è² è· (50 clients, 10000 requests)\n",
      "  3. heavy: é«˜è² è· (100 clients, 50000 requests)\n"
     ]
    }
   ],
   "source": [
    "# åˆ©ç”¨å¯èƒ½ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤º\n",
    "show_services()\n",
    "print()\n",
    "show_patterns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e2fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâœ… ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚å¿…è¦ã«å¿œã˜ã¦ä¸Šè¨˜ã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "# test_all_services(pattern_name=\"light\")  # ä¾‹: å…¨ã‚µãƒ¼ãƒ“ã‚¹ã®è»½sè² è·ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ\n",
    "run_comprehensive_test()  # ä¾‹: å…¨ã‚µãƒ¼ãƒ“ã‚¹ã®å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd4331",
   "metadata": {},
   "source": [
    "## ğŸ“Š çµæœã«ã¤ã„ã¦\n",
    "\n",
    "ãƒ†ã‚¹ãƒˆçµæœã¯ä»¥ä¸‹ã®å ´æ‰€ã«ä¿å­˜ã•ã‚Œã¾ã™ï¼š\n",
    "\n",
    "- **JSONãƒ•ã‚¡ã‚¤ãƒ«**: `analysis/data/*.json` - å®Œå…¨ãªçµæœãƒ‡ãƒ¼ã‚¿\n",
    "- **CSVãƒ•ã‚¡ã‚¤ãƒ«**: `analysis/data/*.csv` - æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼ˆåˆ†æç”¨ï¼‰\n",
    "\n",
    "çµæœã®åˆ†æã«ã¯ `analyze_results.ipynb` ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "### æ¸¬å®šé …ç›®\n",
    "- **ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“**: å¹³å‡ã€ä¸­å¤®å€¤ã€95%tileã€99%tile\n",
    "- **ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: QPSï¼ˆQuery Per Secondï¼‰\n",
    "- **ã‚¨ãƒ©ãƒ¼ç‡**: å¤±æ•—ã—ãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‰²åˆ\n",
    "- **ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡**: CPUã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆå¯èƒ½ãªå ´åˆï¼‰\n",
    "\n",
    "### æ³¨æ„äº‹é …\n",
    "- ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã¯ä»–ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½¿ç”¨ã‚’æ§ãˆã¦ãã ã•ã„\n",
    "- é«˜è² è·ãƒ†ã‚¹ãƒˆã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™\n",
    "- Dockerç’°å¢ƒãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’äº‹å‰ã«ç¢ºèªã—ã¦ãã ã•ã„"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
