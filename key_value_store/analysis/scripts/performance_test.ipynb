{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d476bb7",
   "metadata": {},
   "source": [
    "# Key-Value Store Performance Testing\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯å„Key-Valueã‚¹ãƒˆã‚¢ã‚µãƒ¼ãƒ“ã‚¹ã®æ€§èƒ½ãƒ†ã‚¹ãƒˆã‚’è‡ªå‹•åŒ–ã—ã¾ã™ã€‚\n",
    "\n",
    "## å¯¾è±¡ã‚µãƒ¼ãƒ“ã‚¹\n",
    "1. **1-coordinator-ring**: ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ãƒªãƒ³ã‚°å®Ÿè£…\n",
    "2. **2-quorum-consistency**: ã‚¯ã‚©ãƒ¼ãƒ©ãƒ ä¸€è²«æ€§å®Ÿè£…\n",
    "3. **3-sharding-replica**: ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ»ãƒ¬ãƒ—ãƒªã‚«å®Ÿè£…\n",
    "4. **4-distributed-lock**: åˆ†æ•£ãƒ­ãƒƒã‚¯å®Ÿè£…\n",
    "5. **5-cache-aside**: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰å®Ÿè£…\n",
    "6. **6-bloom-sstable**: Bloomãƒ•ã‚£ãƒ«ã‚¿ã¨SSTableå®Ÿè£…\n",
    "7. **7-rate-limiting**: ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒ†ã‚£ãƒ³ã‚°å®Ÿè£…\n",
    "8. **8-line-streams**: Lineé¢¨ã‚¹ãƒˆãƒªãƒ¼ãƒ å®Ÿè£…\n",
    "9. **9-session-store**: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒˆã‚¢å®Ÿè£…\n",
    "10. **10-leaderboard**: ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰å®Ÿè£…\n",
    "\n",
    "## ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³\n",
    "- **è»½è² è·**: 10 clients, 1000 requests\n",
    "- **ä¸­è² è·**: 50 clients, 10000 requests  \n",
    "- **é«˜è² è·**: 100 clients, 50000 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7422c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import subprocess\n",
    "import requests\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import docker\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# ãƒ­ã‚°è¨­å®š\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ãƒ‘ã‚¹è¨­å®š\n",
    "BASE_DIR = Path(\"/Users/codefox/workspace/practice_infra_arch/key_value_store\")\n",
    "DATA_DIR = BASE_DIR / \"analysis\" / \"data\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"âœ… å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SERVICES å®šç¾© ---\n",
    "SERVICES = {\n",
    "    \"1-coordinator-ring\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"write\": \"/write\",\n",
    "            \"read\": \"/read\"\n",
    "        },\n",
    "        \"test_data\": {\"key\": \"test_key\", \"value\": \"test_value\"}\n",
    "    },\n",
    "    \"2-quorum-consistency\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"write\": \"/write\",\n",
    "            \"read\": \"/read\"\n",
    "        },\n",
    "        \"test_data\": {\"key\": \"test_key\", \"value\": \"test_value\"}\n",
    "    },\n",
    "    \"3-sharding-replica\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"write\": \"/write\",\n",
    "            \"read\": \"/read\"\n",
    "        },\n",
    "        \"test_data\": {\"key\": \"test_key\", \"value\": \"test_value\"}\n",
    "    },\n",
    "    \"4-distributed-lock\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/stats\",\n",
    "            \"acquire\": \"/acquire\",\n",
    "            \"release\": \"/release\"\n",
    "        },\n",
    "        \"test_data\": {\"key\": \"test_resource\", \"owner\": \"test_client\"}\n",
    "    },\n",
    "    \"5-cache-aside\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"get\": \"/get\",\n",
    "            \"set\": \"/set\"\n",
    "        },\n",
    "        \"test_data\": {\"entity_type\": \"user\", \"entity_id\": \"1\", \"data\": {\"name\": \"test\"}}\n",
    "    },\n",
    "    \"6-bloom-sstable\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"write\": \"/write\",\n",
    "            \"read\": \"/read\"\n",
    "        },\n",
    "        \"test_data\": {\"key\": \"test_key\", \"value\": \"test_value\"}\n",
    "    },\n",
    "    \"7-rate-limiting\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"check\": \"/check_rate\"\n",
    "        },\n",
    "        \"test_data\": {\"user_id\": \"test_user\"}\n",
    "    },\n",
    "    \"8-line-streams\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"produce\": \"/produce\",\n",
    "            \"consume\": \"/consume\"\n",
    "        },\n",
    "        \"test_data\": {\"message\": \"test_message\", \"consumer\": \"test_consumer\"}\n",
    "    },\n",
    "    \"9-session-store\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"login\": \"/login\",\n",
    "            \"me\": \"/me\"\n",
    "        },\n",
    "        \"test_data\": {\"username\": \"test_user\"}\n",
    "    },\n",
    "    \"10-leaderboard\": {\n",
    "        \"port\": 8000,\n",
    "        \"endpoints\": {\n",
    "            \"health\": \"/health\",\n",
    "            \"score\": \"/score\",\n",
    "            \"top\": \"/top/10\"\n",
    "        },\n",
    "        \"test_data\": {\"user_id\": \"test_user\", \"score\": 100}\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"SERVICES configured with\", len(SERVICES), \"services\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23be3da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATTERNS = {\n",
    "    \"light\": {\n",
    "        \"description\": \"è»½è² è·\",\n",
    "        \"clients\": 10,\n",
    "        \"requests\": 1000,\n",
    "        \"timeout\": 30,\n",
    "        \"ramp_up\": 5\n",
    "    },\n",
    "    \"medium\": {\n",
    "        \"description\": \"ä¸­è² è·\",\n",
    "        \"clients\": 50, \n",
    "        \"requests\": 10000,\n",
    "        \"timeout\": 60,\n",
    "        \"ramp_up\": 10\n",
    "    },\n",
    "    \"heavy\": {\n",
    "        \"description\": \"é«˜è² è·\",\n",
    "        \"clients\": 100,\n",
    "        \"requests\": 50000,\n",
    "        \"timeout\": 120,\n",
    "        \"ramp_up\": 20\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73efcc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DockerManager:\n",
    "    \"\"\"Dockerã‚³ãƒ³ãƒ†ãƒŠã®ç®¡ç†ã‚¯ãƒ©ã‚¹\"\"\"\n",
    "    \n",
    "    def __init__(self, service_name):\n",
    "        self.service_name = service_name\n",
    "        self.service_dir = BASE_DIR / service_name\n",
    "        self.client = docker.from_env()\n",
    "        \n",
    "    def start_service(self):\n",
    "        \"\"\"ã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•\"\"\"\n",
    "        logger.info(f\"ğŸš€ {self.service_name} ã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•ä¸­...\")\n",
    "        try:\n",
    "            cmd = [\"docker\", \"compose\", \"up\", \"-d\", \"--build\"]\n",
    "            result = subprocess.run(\n",
    "                cmd, \n",
    "                cwd=self.service_dir, \n",
    "                capture_output=True, \n",
    "                text=True,\n",
    "                timeout=300  # 5åˆ†ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ\n",
    "            )\n",
    "            \n",
    "            if result.returncode != 0:\n",
    "                logger.error(f\"âŒ {self.service_name} èµ·å‹•å¤±æ•—: {result.stderr}\")\n",
    "                return False\n",
    "                \n",
    "            logger.info(f\"âœ… {self.service_name} ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•å®Œäº†\")\n",
    "            return True\n",
    "            \n",
    "        except subprocess.TimeoutExpired:\n",
    "            logger.error(f\"âŒ {self.service_name} èµ·å‹•ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ {self.service_name} èµ·å‹•ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def stop_service(self):\n",
    "        \"\"\"ã‚µãƒ¼ãƒ“ã‚¹ã‚’åœæ­¢\"\"\"\n",
    "        logger.info(f\"ğŸ›‘ {self.service_name} ã‚µãƒ¼ãƒ“ã‚¹ã‚’åœæ­¢ä¸­...\")\n",
    "        try:\n",
    "            cmd = [\"docker\", \"compose\", \"down\", \"-v\"]\n",
    "            result = subprocess.run(\n",
    "                cmd, \n",
    "                cwd=self.service_dir, \n",
    "                capture_output=True, \n",
    "                text=True,\n",
    "                timeout=60\n",
    "            )\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                logger.info(f\"âœ… {self.service_name} ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢å®Œäº†\")\n",
    "            else:\n",
    "                logger.warning(f\"âš ï¸ {self.service_name} åœæ­¢æ™‚ã«è­¦å‘Š: {result.stderr}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ {self.service_name} åœæ­¢ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "    \n",
    "    def health_check(self, max_retries=30):\n",
    "        \"\"\"ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯\"\"\"\n",
    "        service_config = SERVICES[self.service_name]\n",
    "        health_url = f\"http://localhost:{service_config['port']}{service_config['endpoints']['health']}\"\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = requests.get(health_url, timeout=5)\n",
    "                if response.status_code == 200:\n",
    "                    logger.info(f\"âœ… {self.service_name} ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯æˆåŠŸ\")\n",
    "                    return True\n",
    "            except requests.exceptions.RequestException:\n",
    "                pass\n",
    "                \n",
    "            time.sleep(2)\n",
    "            logger.info(f\"â³ {self.service_name} ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¾…æ©Ÿä¸­... ({attempt + 1}/{max_retries})\")\n",
    "        \n",
    "        logger.error(f\"âŒ {self.service_name} ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¤±æ•—\")\n",
    "        return False\n",
    "    \n",
    "    def get_container_stats(self):\n",
    "        \"\"\"ã‚³ãƒ³ãƒ†ãƒŠã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—\"\"\"\n",
    "        try:\n",
    "            containers = self.client.containers.list(filters={\"label\": f\"com.docker.compose.project={self.service_name.replace('-', '')}\"})\n",
    "            stats = {}\n",
    "            \n",
    "            for container in containers:\n",
    "                container_stats = container.stats(stream=False)\n",
    "                stats[container.name] = {\n",
    "                    \"cpu_percent\": self._calculate_cpu_percent(container_stats),\n",
    "                    \"memory_usage\": container_stats[\"memory\"][\"usage\"],\n",
    "                    \"memory_limit\": container_stats[\"memory\"][\"limit\"]\n",
    "                }\n",
    "            return stats\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"âš ï¸ {self.service_name} çµ±è¨ˆæƒ…å ±å–å¾—å¤±æ•—: {str(e)}\")\n",
    "            return {}\n",
    "    \n",
    "    def _calculate_cpu_percent(self, stats):\n",
    "        \"\"\"CPUä½¿ç”¨ç‡ã‚’è¨ˆç®—\"\"\"\n",
    "        try:\n",
    "            cpu_delta = stats[\"cpu_stats\"][\"cpu_usage\"][\"total_usage\"] - stats[\"precpu_stats\"][\"cpu_usage\"][\"total_usage\"]\n",
    "            system_delta = stats[\"cpu_stats\"][\"system_cpu_usage\"] - stats[\"precpu_stats\"][\"system_cpu_usage\"]\n",
    "            num_cpus = len(stats[\"cpu_stats\"][\"cpu_usage\"][\"percpu_usage\"])\n",
    "            \n",
    "            if system_delta > 0:\n",
    "                return (cpu_delta / system_delta) * num_cpus * 100.0\n",
    "        except (KeyError, ZeroDivisionError):\n",
    "            pass\n",
    "        return 0.0\n",
    "\n",
    "@contextmanager\n",
    "def service_context(service_name):\n",
    "    \"\"\"ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼\"\"\"\n",
    "    docker_manager = DockerManager(service_name)\n",
    "    docker_manager.stop_service()\n",
    "    \n",
    "    try:\n",
    "        # ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•\n",
    "        if not docker_manager.start_service():\n",
    "            raise RuntimeError(f\"Failed to start {service_name}\")\n",
    "        \n",
    "        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯\n",
    "        if not docker_manager.health_check():\n",
    "            raise RuntimeError(f\"Health check failed for {service_name}\")\n",
    "        \n",
    "        yield docker_manager\n",
    "        \n",
    "    finally:\n",
    "        # ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢\n",
    "        docker_manager.stop_service()\n",
    "        # ã‚¯ãƒ¼ãƒ«ã‚¿ã‚¤ãƒ : ã‚³ãƒ³ãƒ†ãƒŠã®å®Œå…¨è§£æ”¾ / ãƒãƒ¼ãƒˆè§£æ”¾å¾…ã¡\n",
    "        logger.info(f\"â³ {service_name} åœæ­¢å¾Œã®ã‚¯ãƒ¼ãƒ«ã‚¿ã‚¤ãƒ : 60ç§’å¾…æ©Ÿã—ã¾ã™...\")\n",
    "        time.sleep(60)\n",
    "\n",
    "print(\"âœ… Dockerç®¡ç†ã‚¯ãƒ©ã‚¹ãŒå®šç¾©ã•ã‚Œã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897224a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceTester:\n",
    "    \"\"\"æ€§èƒ½ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¯ãƒ©ã‚¹\"\"\"\n",
    "    \n",
    "    def __init__(self, service_name):\n",
    "        self.service_name = service_name\n",
    "        self.service_config = SERVICES[service_name]\n",
    "        self.base_url = f\"http://localhost:{self.service_config['port']}\"\n",
    "        self.results = []\n",
    "        \n",
    "    def run_single_request(self, endpoint, method=\"GET\", data=None):\n",
    "        \"\"\"å˜ä¸€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å®Ÿè¡Œã¨æ¸¬å®š\"\"\"\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            if method == \"POST\":\n",
    "                response = requests.post(url, json=data, timeout=10)\n",
    "            else:\n",
    "                response = requests.get(url, params=data, timeout=10)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            response_time = (end_time - start_time) * 1000  # ãƒŸãƒªç§’\n",
    "            \n",
    "            return {\n",
    "                \"response_time\": response_time,\n",
    "                \"status_code\": response.status_code,\n",
    "                \"success\": 200 <= response.status_code < 300,\n",
    "                \"error\": None\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            end_time = time.time()\n",
    "            response_time = (end_time - start_time) * 1000\n",
    "            \n",
    "            return {\n",
    "                \"response_time\": response_time,\n",
    "                \"status_code\": 0,\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    def run_load_test(self, pattern_name, docker_manager):\n",
    "        \"\"\"è² è·ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ\"\"\"\n",
    "        pattern = TEST_PATTERNS[pattern_name]\n",
    "        clients = pattern[\"clients\"]\n",
    "        total_requests = pattern[\"requests\"]\n",
    "        requests_per_client = total_requests // clients\n",
    "        \n",
    "        logger.info(f\"ğŸ§ª {self.service_name} - {pattern['description']} é–‹å§‹\")\n",
    "        logger.info(f\"   ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ•°: {clients}, ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {total_requests}\")\n",
    "        \n",
    "        # ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ±ºå®š\n",
    "        test_endpoint, test_method, test_data = self._get_test_endpoint()\n",
    "        \n",
    "        # åˆæœŸçµ±è¨ˆæƒ…å ±å–å¾—\n",
    "        initial_stats = docker_manager.get_container_stats()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        all_results = []\n",
    "        \n",
    "        # ä¸¦è¡Œãƒ†ã‚¹ãƒˆå®Ÿè¡Œ\n",
    "        with ThreadPoolExecutor(max_workers=clients) as executor:\n",
    "            futures = []\n",
    "            \n",
    "            for client_id in range(clients):\n",
    "                future = executor.submit(\n",
    "                    self._client_worker, \n",
    "                    client_id, \n",
    "                    requests_per_client, \n",
    "                    test_endpoint, \n",
    "                    test_method, \n",
    "                    test_data\n",
    "                )\n",
    "                futures.append(future)\n",
    "            \n",
    "            # çµæœåé›†\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    client_results = future.result()\n",
    "                    all_results.extend(client_results)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"âŒ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        total_duration = end_time - start_time\n",
    "        \n",
    "        # æœ€çµ‚çµ±è¨ˆæƒ…å ±å–å¾—\n",
    "        final_stats = docker_manager.get_container_stats()\n",
    "        \n",
    "        # çµæœåˆ†æ\n",
    "        analysis = self._analyze_results(all_results, total_duration, initial_stats, final_stats)\n",
    "        analysis.update({\n",
    "            \"service_name\": self.service_name,\n",
    "            \"pattern_name\": pattern_name,\n",
    "            \"pattern_description\": pattern[\"description\"],\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"clients\": clients,\n",
    "            \"total_requests\": len(all_results),\n",
    "            \"duration\": total_duration\n",
    "        })\n",
    "        \n",
    "        logger.info(f\"âœ… {self.service_name} - {pattern['description']} å®Œäº†\")\n",
    "        logger.info(f\"   å®Ÿè¡Œæ™‚é–“: {total_duration:.2f}ç§’, QPS: {analysis['qps']:.2f}\")\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _get_test_endpoint(self):\n",
    "        \"\"\"ã‚µãƒ¼ãƒ“ã‚¹ã”ã¨ã®é©åˆ‡ãªãƒ†ã‚¹ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æ±ºå®š\"\"\"\n",
    "        endpoints = self.service_config[\"endpoints\"]\n",
    "        test_data = self.service_config[\"test_data\"]\n",
    "        \n",
    "        if \"write\" in endpoints:\n",
    "            return endpoints[\"write\"], \"POST\", test_data\n",
    "        elif \"put\" in endpoints:\n",
    "            return endpoints[\"put\"], \"POST\", test_data\n",
    "        elif \"publish\" in endpoints:\n",
    "            return endpoints[\"publish\"], \"POST\", test_data\n",
    "        elif \"produce\" in endpoints:\n",
    "            return endpoints[\"produce\"], \"POST\", test_data\n",
    "        elif \"acquire\" in endpoints:\n",
    "            return endpoints[\"acquire\"], \"POST\", test_data\n",
    "        else:\n",
    "            return endpoints[\"health\"], \"GET\", None\n",
    "    \n",
    "    def _client_worker(self, client_id, requests_count, endpoint, method, data):\n",
    "        \"\"\"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆå„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒå®Ÿè¡Œã™ã‚‹å‡¦ç†ï¼‰\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for i in range(requests_count):\n",
    "            # ãƒ‡ãƒ¼ã‚¿ã®å‹•çš„ç”Ÿæˆï¼ˆä¸€æ„æ€§ç¢ºä¿ï¼‰\n",
    "            if data:\n",
    "                test_data = data.copy()\n",
    "                if \"key\" in test_data:\n",
    "                    test_data[\"key\"] = f\"{test_data['key']}_{client_id}_{i}\"\n",
    "                if \"resource\" in test_data:\n",
    "                    test_data[\"resource\"] = f\"{test_data['resource']}_{client_id}_{i}\"\n",
    "                if \"client_id\" in test_data:\n",
    "                    test_data[\"client_id\"] = f\"{test_data['client_id']}_{client_id}\"\n",
    "            else:\n",
    "                test_data = None\n",
    "            \n",
    "            result = self.run_single_request(endpoint, method, test_data)\n",
    "            result[\"client_id\"] = client_id\n",
    "            result[\"request_id\"] = i\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _analyze_results(self, results, duration, initial_stats, final_stats):\n",
    "        \"\"\"çµæœåˆ†æ\"\"\"\n",
    "        successful_results = [r for r in results if r[\"success\"]]\n",
    "        response_times = [r[\"response_time\"] for r in successful_results]\n",
    "        \n",
    "        if not response_times:\n",
    "            return {\n",
    "                \"total_requests\": len(results),\n",
    "                \"successful_requests\": 0,\n",
    "                \"error_rate\": 100.0,\n",
    "                \"qps\": 0.0,\n",
    "                \"avg_response_time\": 0.0,\n",
    "                \"median_response_time\": 0.0,\n",
    "                \"p95_response_time\": 0.0,\n",
    "                \"p99_response_time\": 0.0,\n",
    "                \"min_response_time\": 0.0,\n",
    "                \"max_response_time\": 0.0\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"total_requests\": len(results),\n",
    "            \"successful_requests\": len(successful_results),\n",
    "            \"error_rate\": ((len(results) - len(successful_results)) / len(results)) * 100,\n",
    "            \"qps\": len(successful_results) / duration,\n",
    "            \"avg_response_time\": statistics.mean(response_times),\n",
    "            \"median_response_time\": statistics.median(response_times),\n",
    "            \"p95_response_time\": np.percentile(response_times, 95),\n",
    "            \"p99_response_time\": np.percentile(response_times, 99),\n",
    "            \"min_response_time\": min(response_times),\n",
    "            \"max_response_time\": max(response_times),\n",
    "            \"initial_stats\": initial_stats,\n",
    "            \"final_stats\": final_stats\n",
    "        }\n",
    "\n",
    "print(\"âœ… æ€§èƒ½ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ãŒå®šç¾©ã•ã‚Œã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d1034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comprehensive_test(selected_services=None, selected_patterns=None):\n",
    "    \"\"\"åŒ…æ‹¬çš„ãªæ€§èƒ½ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ\"\"\"\n",
    "    if selected_services is None:\n",
    "        selected_services = list(SERVICES.keys())\n",
    "    if selected_patterns is None:\n",
    "        selected_patterns = list(TEST_PATTERNS.keys())\n",
    "    \n",
    "    all_results = []\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    logger.info(f\"ğŸš€ åŒ…æ‹¬çš„æ€§èƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹ - {timestamp}\")\n",
    "    logger.info(f\"å¯¾è±¡ã‚µãƒ¼ãƒ“ã‚¹: {selected_services}\")\n",
    "    logger.info(f\"ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³: {selected_patterns}\")\n",
    "    \n",
    "    total_tests = len(selected_services) * len(selected_patterns)\n",
    "    current_test = 0\n",
    "    \n",
    "    for service_name in selected_services:\n",
    "        logger.info(f\"\\nğŸ“Š {service_name} ã®ãƒ†ã‚¹ãƒˆé–‹å§‹\")\n",
    "        \n",
    "        try:\n",
    "            with service_context(service_name) as docker_manager:\n",
    "                tester = PerformanceTester(service_name)\n",
    "                \n",
    "                for pattern_name in selected_patterns:\n",
    "                    current_test += 1\n",
    "                    logger.info(f\"\\né€²è¡ŒçŠ¶æ³: {current_test}/{total_tests}\")\n",
    "                    \n",
    "                    try:\n",
    "                        result = tester.run_load_test(pattern_name, docker_manager)\n",
    "                        all_results.append(result)\n",
    "                        \n",
    "                        # ä¸­é–“çµæœä¿å­˜\n",
    "                        save_results([result], f\"intermediate_{service_name}_{pattern_name}_{timestamp}\")\n",
    "                        \n",
    "                        # ãƒ†ã‚¹ãƒˆé–“ã®ä¼‘æ†©\n",
    "                        if current_test < total_tests:\n",
    "                            logger.info(\"â¸ï¸ 5ç§’é–“ã®ä¼‘æ†©...\")\n",
    "                            time.sleep(5)\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"âŒ {service_name} - {pattern_name} ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}\")\n",
    "                        # ã‚¨ãƒ©ãƒ¼çµæœã‚‚è¨˜éŒ²\n",
    "                        error_result = {\n",
    "                            \"service_name\": service_name,\n",
    "                            \"pattern_name\": pattern_name,\n",
    "                            \"error\": str(e),\n",
    "                            \"timestamp\": datetime.now().isoformat()\n",
    "                        }\n",
    "                        all_results.append(error_result)\n",
    "                        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ {service_name} ã‚µãƒ¼ãƒ“ã‚¹å…¨ä½“ã®ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # æœ€çµ‚çµæœä¿å­˜\n",
    "    save_results(all_results, f\"comprehensive_test_{timestamp}\")\n",
    "    \n",
    "    logger.info(f\"\\nğŸ‰ å…¨ãƒ†ã‚¹ãƒˆå®Œäº†! çµæœã¯ {DATA_DIR} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ\")\n",
    "    return all_results\n",
    "\n",
    "def save_results(results, filename_prefix):\n",
    "    \"\"\"çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\"\"\"\n",
    "    # JSONå½¢å¼ã§ä¿å­˜\n",
    "    json_file = DATA_DIR / f\"{filename_prefix}.json\"\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # CSVå½¢å¼ã§ä¿å­˜ï¼ˆæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰\n",
    "    csv_file = DATA_DIR / f\"{filename_prefix}.csv\"\n",
    "    \n",
    "    if results and not any('error' in r for r in results):\n",
    "        # ã‚¨ãƒ©ãƒ¼ãŒãªã„å ´åˆã®ã¿CSVå‡ºåŠ›\n",
    "        df = pd.DataFrame(results)\n",
    "        # è¤‡é›‘ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’é™¤å¤–\n",
    "        numeric_columns = df.select_dtypes(include=[np.number, 'object']).columns\n",
    "        simple_columns = [col for col in numeric_columns \n",
    "                         if col not in ['initial_stats', 'final_stats']]\n",
    "        df[simple_columns].to_csv(csv_file, index=False)\n",
    "    \n",
    "    logger.info(f\"ğŸ’¾ çµæœä¿å­˜å®Œäº†: {json_file}\")\n",
    "\n",
    "print(\"âœ… ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–¢æ•°ãŒå®šç¾©ã•ã‚Œã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24613c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç”¨é–¢æ•°\n",
    "\n",
    "def show_services():\n",
    "    \"\"\"åˆ©ç”¨å¯èƒ½ãªã‚µãƒ¼ãƒ“ã‚¹ä¸€è¦§ã‚’è¡¨ç¤º\"\"\"\n",
    "    print(\"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªã‚µãƒ¼ãƒ“ã‚¹:\")\n",
    "    for i, (name, config) in enumerate(SERVICES.items(), 1):\n",
    "        print(f\"  {i}. {name} (ãƒãƒ¼ãƒˆ: {config['port']})\")\n",
    "\n",
    "def show_patterns():\n",
    "    \"\"\"åˆ©ç”¨å¯èƒ½ãªãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§ã‚’è¡¨ç¤º\"\"\"\n",
    "    print(\"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³:\")\n",
    "    for i, (name, pattern) in enumerate(TEST_PATTERNS.items(), 1):\n",
    "        print(f\"  {i}. {name}: {pattern['description']} ({pattern['clients']} clients, {pattern['requests']} requests)\")\n",
    "\n",
    "def quick_test(service_name, pattern_name=\"light\"):\n",
    "    \"\"\"å˜ä¸€ã‚µãƒ¼ãƒ“ã‚¹ã®ç°¡æ˜“ãƒ†ã‚¹ãƒˆ\"\"\"\n",
    "    if service_name not in SERVICES:\n",
    "        print(f\"âŒ ã‚µãƒ¼ãƒ“ã‚¹ '{service_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        show_services()\n",
    "        return None\n",
    "    \n",
    "    if pattern_name not in TEST_PATTERNS:\n",
    "        print(f\"âŒ ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        show_patterns()\n",
    "        return None\n",
    "    \n",
    "    return run_comprehensive_test([service_name], [pattern_name])\n",
    "\n",
    "def test_all_services(pattern_name=\"light\"):\n",
    "    \"\"\"å…¨ã‚µãƒ¼ãƒ“ã‚¹ã®æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã®ãƒ†ã‚¹ãƒˆ\"\"\"\n",
    "    if pattern_name not in TEST_PATTERNS:\n",
    "        print(f\"âŒ ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        show_patterns()\n",
    "        return None\n",
    "    \n",
    "    return run_comprehensive_test(None, [pattern_name])\n",
    "\n",
    "def test_service_all_patterns(service_name):\n",
    "    \"\"\"æŒ‡å®šã‚µãƒ¼ãƒ“ã‚¹ã®å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã®ãƒ†ã‚¹ãƒˆ\"\"\"\n",
    "    if service_name not in SERVICES:\n",
    "        print(f\"âŒ ã‚µãƒ¼ãƒ“ã‚¹ '{service_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        show_services()\n",
    "        return None\n",
    "    \n",
    "    return run_comprehensive_test([service_name], None)\n",
    "\n",
    "print(\"âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹é–¢æ•°ãŒå®šç¾©ã•ã‚Œã¾ã—ãŸ\")\n",
    "print(\"\\nğŸ¯ ä½¿ç”¨æ–¹æ³•:\")\n",
    "print(\"  - show_services(): ã‚µãƒ¼ãƒ“ã‚¹ä¸€è¦§è¡¨ç¤º\")\n",
    "print(\"  - show_patterns(): ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§è¡¨ç¤º\")\n",
    "print(\"  - quick_test('service_name', 'pattern_name'): å˜ä¸€ã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ\")\n",
    "print(\"  - test_all_services('pattern_name'): å…¨ã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ\")\n",
    "print(\"  - test_service_all_patterns('service_name'): æŒ‡å®šã‚µãƒ¼ãƒ“ã‚¹å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ\")\n",
    "print(\"  - run_comprehensive_test(): å®Œå…¨ãªã‚«ã‚¹ã‚¿ãƒ ãƒ†ã‚¹ãƒˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fa8002",
   "metadata": {},
   "source": [
    "## ğŸš€ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¾‹\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚ãƒ†ã‚¹ãƒˆå‰ã«å¿…è¦ã«å¿œã˜ã¦è¨­å®šã‚’ç¢ºèªãƒ»å¤‰æ›´ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4724dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ©ç”¨å¯èƒ½ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤º\n",
    "show_services()\n",
    "print()\n",
    "show_patterns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bc5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   1. 1-coordinator-ring\n",
    "#   2. 2-quorum-consistency\n",
    "#   3. 3-sharding-replica\n",
    "#   4. 4-distributed-lock\n",
    "#   5. 5-cache-aside\n",
    "#   6. 6-bloom-sstable\n",
    "#   7. 7-rate-limiting\n",
    "#   8. 8-line-streams\n",
    "#   9. 9-session-store\n",
    "#   10. 10-leaderboard\n",
    "\n",
    "# ä¾‹: å˜ä¸€ã‚µãƒ¼ãƒ“ã‚¹ã®è»½è² è·ãƒ†ã‚¹ãƒˆ\n",
    "quick_test(\"2-quorum-consistency\", \"light\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c59f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¾‹: å…¨ã‚µãƒ¼ãƒ“ã‚¹ã®è»½è² è·ãƒ†ã‚¹ãƒˆ\n",
    "test_all_services(\"light\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f0f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¾‹: åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆï¼ˆå…¨ã‚µãƒ¼ãƒ“ã‚¹ã€å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰\n",
    "# âš ï¸ æ³¨æ„: ã“ã®ãƒ†ã‚¹ãƒˆã¯éå¸¸ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼ˆ1-2æ™‚é–“ç¨‹åº¦ï¼‰\n",
    "# results = run_comprehensive_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd4331",
   "metadata": {},
   "source": [
    "## ğŸ“Š çµæœã«ã¤ã„ã¦\n",
    "\n",
    "ãƒ†ã‚¹ãƒˆçµæœã¯ä»¥ä¸‹ã®å ´æ‰€ã«ä¿å­˜ã•ã‚Œã¾ã™ï¼š\n",
    "\n",
    "- **JSONãƒ•ã‚¡ã‚¤ãƒ«**: `analysis/data/*.json` - å®Œå…¨ãªçµæœãƒ‡ãƒ¼ã‚¿\n",
    "- **CSVãƒ•ã‚¡ã‚¤ãƒ«**: `analysis/data/*.csv` - æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼ˆåˆ†æç”¨ï¼‰\n",
    "\n",
    "çµæœã®åˆ†æã«ã¯ `analyze_results.ipynb` ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "### æ¸¬å®šé …ç›®\n",
    "- **ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“**: å¹³å‡ã€ä¸­å¤®å€¤ã€95%tileã€99%tile\n",
    "- **ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: QPSï¼ˆQuery Per Secondï¼‰\n",
    "- **ã‚¨ãƒ©ãƒ¼ç‡**: å¤±æ•—ã—ãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‰²åˆ\n",
    "- **ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡**: CPUã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆå¯èƒ½ãªå ´åˆï¼‰\n",
    "\n",
    "### æ³¨æ„äº‹é …\n",
    "- ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã¯ä»–ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½¿ç”¨ã‚’æ§ãˆã¦ãã ã•ã„\n",
    "- é«˜è² è·ãƒ†ã‚¹ãƒˆã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™\n",
    "- Dockerç’°å¢ƒãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’äº‹å‰ã«ç¢ºèªã—ã¦ãã ã•ã„"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
